{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Big Data Machine Learning, Distributed Machine Learning, Parallel Machine Learning with C++, CUDA, Scala, Spark\n",
    "=============\n",
    "\n",
    "Ron Wu\n",
    "-------------\n",
    "\n",
    "11/2/16\n",
    "\n",
    "Reference: free courses from the creators of\n",
    "<br>NVIDIA https://developer.nvidia.com/udacity-cs344-intro-parallel-programming<br>\n",
    "Scala http://www.scala-lang.org/blog/2016/05/23/scala-moocs-specialization-launched.html<br>\n",
    "Spark, Databricks https://databricks.com/blog/2016/06/01/databricks-to-launch-first-of-five-free-big-data-courses-on-apache-spark.html <br> \n",
    "### Contents\n",
    "\n",
    "\n",
    "1. <a href =#scala>Functional and Object-Oriented Scala = Java + Clojure</a>\n",
    "     - <a href=#scalab>Scala Foundation</a>\n",
    "     \n",
    "         - <a href =#fun>First Class Objects</a>\n",
    "         - <a href=#cl>Classes and the Three Pillars</a>  \n",
    "         - <a href=#obj>Objects Everywhere</a> \n",
    "         - <a href =#collect>Collections</a> \n",
    "     - <a href = #funDe>Functional Design in Scala</a> \n",
    "     \n",
    "         - <a href=#for>For Expression</a>\n",
    "         - <a href=#stream>Stream & Lazy Evaluation</a> \n",
    "         - <a href=#event>Event Handling</a>\n",
    "         - <a href=#ober>Observer Pattern</a> \n",
    "         \n",
    "     - <a href = #pppro>Parallel Programming in Scala</a> \n",
    "         - <a href =#thread>Parallel Threads</a>\n",
    "         - <a href =#par>Parallel Algorithms</a>\n",
    "         - <a href =#dataStr>Parallel Data Structures</a>\n",
    "         - <a href =#akka>Concurrency & Actors Modes</a>\n",
    "<br><br>\n",
    "2. <a href=#Spark>Big Data, Distributed Analysis with Spark</a>\n",
    "     - <a href = #scalaspark>Spark Streaming</a>  \n",
    "         - <a href = #scalaspark>Twitter Sentiment Analysis in Real Time</a>\n",
    "     - <a href =#ssql>Spark SQL</a> \n",
    "         - <a href =#ssql>Page Ranking Application</a>\n",
    "     - <a href =#sml>Spark MLlib</a>  \n",
    "         - <a href =#sml>Movie Recommendation System</a>\n",
    "         - <a href=#otherML>Other Big Data Machine Learning Algorithms & Statistics</a>\n",
    "     - <a href =#Amazon>The Clouds - AWS Ecosystem</a> \n",
    "         - <a href =#Amazon>AWS Ecosystem</a> \n",
    "         - <a href =#google>Google Clouds ML With TensorFlow</a> \n",
    "<br><br>\n",
    "3. <a href =#cuda>Parallel with CUDA, C++</a>\n",
    "     - <a href=#worked>Parallel Computing</a> \n",
    "     - <a href=#worked>GPU Programming</a> \n",
    "<br><br>\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name = 'scala'></a>\n",
    "# Functional and Object-Oriented Scala = Java + Clojure\n",
    "\n",
    "![](https://www.scientiamobile.com/images/icons/scala.gif)\n",
    "\n",
    "\n",
    "<a name = 'scalab'></a>\n",
    "## Scala Foundation\n",
    "\n",
    "\n",
    "The codes in this section are mostly copied from Martin Odersky course on coursera https://www.coursera.org/learn/progfun1/\n",
    "\n",
    "For easier transition to parallel programming, throughout this notebook I will try to use functional style over imperative style whenever possible. That is because in pure functional programming variables are immutable. Once it is set, it cannot be changed, which avoids a lot deadlocks. \n",
    "\n",
    "If a block of code is written in loop fashion, the compiler will turn it into functions, the iteration and any change of variables inside the loop are passing through the function calls. Thus whether you write it in serial or recursion, it will end up in recursive call anyway.  \n",
    "\n",
    "<a name='fun'></a>\n",
    "### First Class Functions\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//it is okay to do this, because def is call-by-name, only definition\n",
    "def loop: Int = loop \n",
    "\n",
    "//Do not run, infinite loop, because val is call-by-value\n",
    "//val l = loop\n",
    "    \n",
    "def square(x: Int) = x*x\n",
    "\n",
    "def squareFirstEle(x: Int, y: => Int) = square(x)\n",
    "// => makes y call-by-name, so passing in loop is okay\n",
    "squareFirstEle(2,loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1224976448422046"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Newton Method (steep descent or fix point) find square root\n",
    "\n",
    "def sqrt(x: Double) = {\n",
    "        \n",
    "    def sqrtIter(guess: Double): Double =\n",
    "        if (math.abs(guess*guess-x) / x < 0.01) guess\n",
    "        else sqrtIter((guess + x / guess) / 2) \n",
    "\n",
    "    sqrtIter(1.0)\n",
    "}\n",
    "\n",
    "sqrt(4.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//  High order function  \n",
    "\n",
    "def sum_v1(f: Int => Int, a: Int, b: Int): Int = {\n",
    "    if (a > b) 0\n",
    "    else sum_v1(f, a+1, b) + f(a)\n",
    "}\n",
    "\n",
    "\n",
    "// find the sum of the squares from 1 to 5 \n",
    "sum_v1(square, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// rectify above to tail-recursion, so will not build up the stack\n",
    "    \n",
    "def sum_v2(f: Int => Int, a: Int, b: Int): Int = {\n",
    "    def loop(a: Int, acc: Int): Int = {\n",
    "        if (a > b) acc\n",
    "        else loop(a+1, acc + f(a))\n",
    "    }\n",
    "    loop(a, 0)\n",
    "}\n",
    "\n",
    "sum_v2(square, 1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// sum_v3 is a pure functional\n",
    "    \n",
    "def sum_v3(f: Int => Int): (Int, Int) => Int =  {\n",
    "        def sumF(a: Int, b: Int): Int = { \n",
    "            if (a>b) 0\n",
    "            else sumF(a+1,b) + f(a)\n",
    "        }\n",
    "        sumF\n",
    "}\n",
    "\n",
    "// passing in anonymous\n",
    "sum_v3(x => x*x)(1, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name='cl'></a>\n",
    "### Classes and the Three Pillars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r rational: 1/2\n",
      "negative of s rational: -1/2\n",
      "sum of rationals r & s: 5/4\n",
      "integer t: 2\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// Encapsulation\n",
    "//\n",
    "\n",
    "class Rational(x: Int, y: Int)  {\n",
    "    require( y != 0 , \"denominator not to be zero\")\n",
    "\n",
    "    //second constructor\n",
    "    def this(x: Int) = this(x, 1)\n",
    "\n",
    "    private def gcd(a:Int, b:Int) : Int =\n",
    "    //Euler method\n",
    "        if (b==0) a\n",
    "        else gcd(b, a%b)\n",
    "    private val g = math.abs(gcd(x, y))\n",
    "\n",
    "    val numer = x / g\n",
    "    val denom = y / g\n",
    "\n",
    "\n",
    "    override def toString =\n",
    "        if (y!=1) this.numer + \"/\" + this.denom\n",
    "        else (this.numer).toString\n",
    "\n",
    "    //normally + cannot be identifier, but in Scala is legal\n",
    "    def + (that: Rational) =\n",
    "        new Rational(this.numer*that.denom+this.denom*that.numer, this .denom*that.denom)\n",
    "\n",
    "    def unary_- = new Rational(-numer, denom)\n",
    "\n",
    "}\n",
    "\n",
    "val r = new Rational(1,2)\n",
    "println(\"r rational: \" + r.toString)\n",
    "\n",
    "\n",
    "val s = new Rational(3,4)\n",
    "\n",
    "// this - is special it right next to the object, so use unary_-\n",
    "println(\"negative of s rational: \"+(-r).toString)\n",
    "\n",
    "//this is same as (r.+(s)).toString\n",
    "println(\"sum of rationals r & s: \" + (r + s).toString)\n",
    "\n",
    "val t = new Rational(2)\n",
    "println(\"integer t: \"+t.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{-3-}\n",
      "{-3{-4-}}\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "//  inheritance\n",
    "//\n",
    "\n",
    "abstract class Node{\n",
    "    def insert(x: Int) : Node\n",
    "    def search(x: Int) : Boolean\n",
    "}\n",
    "\n",
    "//Java supports only single inheritance. For multiple, use with traits\n",
    "\n",
    "//so the default constructor takes 3 arguments\n",
    "class NonEmpty(elem: Int, left: Node, right: Node)  extends Node{\n",
    "\n",
    "\n",
    "    def insert(x: Int) : Node = {\n",
    "        if ( x < elem ) new NonEmpty(elem, left insert x , right)\n",
    "        else if (x > elem) new NonEmpty(elem, left, right insert x)\n",
    "        else this\n",
    "    }\n",
    "\n",
    "    def search(x: Int) : Boolean = {\n",
    "        if ( x < elem ) left search x\n",
    "        else if ( x > elem ) right search x\n",
    "        else true\n",
    "    }\n",
    "    \n",
    "    // because of override in Empty, override left toString will be called\n",
    "    override def toString = \"{\" + left + elem + right + \"}\"\n",
    "}    \n",
    "\n",
    "class Empty extends Node{\n",
    "\n",
    "    def insert(x: Int) : Node = new NonEmpty(x, new Empty, new Empty)\n",
    "    def search(x: Int) : Boolean = false\n",
    "    override def toString = \"-\"\n",
    "}\n",
    "\n",
    "val tree1 = new NonEmpty(3, new Empty, new  Empty)\n",
    "\n",
    "// a copy of tree1 with 4 inserted\n",
    "val tree2 = tree1 insert 4  \n",
    "\n",
    "println(tree1.toString)\n",
    "println(tree2.toString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "//  Polymorphism\n",
    "//\n",
    "\n",
    "import java.util.NoSuchElementException \n",
    "\n",
    "//type parameter\n",
    "trait Node[T]{\n",
    "    def isEmpty: Boolean\n",
    "    def data: T\n",
    "    def pt: Node[T]\n",
    "}\n",
    "\n",
    "\n",
    "//the default constructor takes 2 arguments\n",
    "//this also means that 2 corresponding fields of the class are\n",
    "//defined through pass in variables\n",
    "class Cons[T](val data: T, val pt: Node[T]) extends Node[T]{\n",
    "    def isEmpty = false\n",
    "}\n",
    "\n",
    "class Nil[T] extends Node[T]{\n",
    "    def isEmpty = true\n",
    "    def data : Nothing = throw new NoSuchElementException(\"Nil.data\")\n",
    "    def pt: Nothing = throw new NoSuchElementException(\"Nil.pt\")\n",
    "}\n",
    "\n",
    "def singleton[T](elem:T) = new Cons[T](elem, new Nil[T])\n",
    "\n",
    "println(singleton[Double](1.1).data)\n",
    "\n",
    "\n",
    "// this will threw exception\n",
    "// println(singleton[Double](1.1).pt.data)\n",
    "\n",
    "\n",
    "//the type parameter is redundant \n",
    "val ll = new Cons(3, new Cons(2, new Cons(1, new Nil)))\n",
    "\n",
    "println(ll.data)\n",
    "println(ll.pt.data)\n",
    "println(ll.pt.pt.data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='ooscala'></a> \n",
    "## Object-Oriented Aspect of Scala\n",
    "\n",
    "\n",
    "<a name ='obj'></a>\n",
    "### Objects Everywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "III\n",
      "II\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    "    this cell can only run once, because it has static object\n",
    "*/\n",
    "\n",
    "// This shows unsigned Int, a primitive type, can be represented as class object\n",
    "// This is the same idea in Number theory that one can construct every natural number\n",
    "// starting from the empty set\n",
    "\n",
    "abstract class Nat {\n",
    "    def isZero: java.lang.Boolean\n",
    "    def predecessor: Nat\n",
    "    def successor: Nat\n",
    "    def + (that: Nat): Nat\n",
    "    def - (that: Nat): Nat \n",
    "    override def toString: String\n",
    "}\n",
    "\n",
    "\n",
    "class Succ(n: Nat) extends Nat{\n",
    "    def isZero = false\n",
    "    def predecessor = n\n",
    "    def successor = new Succ(this)\n",
    "    def +(that: Nat) = new Succ(n + that)\n",
    "    def -(that: Nat) = if (that.isZero) this else n - that.predecessor\n",
    "\n",
    "    override def toString: String = \"I\" + n\n",
    "}\n",
    "\n",
    "//hence zero is unique\n",
    "object Zero extends Nat{\n",
    "    def isZero = true\n",
    "    def predecessor = throw new Error(\"0 has no pred\")\n",
    "    def successor = new Succ(this)\n",
    "    def +(that: Nat) = that\n",
    "    def -(that: Nat) = if (that.isZero) this else throw new Error(\"negative number\")\n",
    "\n",
    "    override def toString: String = \"\"\n",
    "}\n",
    "\n",
    "\n",
    "def NextNat = new Succ(Zero)\n",
    "val one = NextNat\n",
    "val two = one.successor\n",
    "val three = two.successor\n",
    "println(three)\n",
    "println(three-one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// Functions as objects too\n",
    "//\n",
    "\n",
    "// function take 1 argument, with type parameters A, B \n",
    "trait Function1[A,B]{\n",
    "    def apply(x : A) : B\n",
    "}\n",
    "\n",
    "\n",
    "def f =  {\n",
    "    // anonymous function \n",
    "    // (x: Int) => x*x\n",
    "    // the name AnonFun only exists inside of the block\n",
    "    class AnonFun extends Function1[Int, Int] {\n",
    "        def apply(x: Int) = x*x\n",
    "    }\n",
    "    new AnonFun\n",
    "}\n",
    "\n",
    "f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Covariance, Invariance and Contravariance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "/*\n",
    "\n",
    "Let us denote type A is derived from type B as\n",
    "\n",
    "    A < B \n",
    "    \n",
    "If f is a type transformation, e.g. A -> Array[A], or work with generic A -> List<A>, \n",
    "\n",
    "Convariance \n",
    "\n",
    "    A < B => f(A) < f(B)\n",
    "\n",
    "controvariance\n",
    "\n",
    "    A < B => f(A) > f(B)\n",
    "    \n",
    "invariance\n",
    "\n",
    "    Neither above.\n",
    "    \n",
    "In Java, Array[] is convariance, and generic is invariance, \n",
    "\n",
    "but in scala, both are not covariant.\n",
    "\n",
    "but just like in Java, one can turn them into co/controvariace by using the wildcards\n",
    "\n",
    "\n",
    "That is\n",
    " \n",
    "    B[] array_b = new A[1]; \n",
    "\n",
    "is allowed and ArrayList<B> list_b = new ArrayList<A>(); is not allowed.\n",
    "\n",
    "and elements of array_b are actually upcasted type A object. This could cause runtime errors.\n",
    "\n",
    "\n",
    "That is\n",
    "\n",
    "        \n",
    "    B b = new A();  // both are fine\n",
    "    \n",
    "    b = new B();\n",
    "        \n",
    "    \n",
    "\n",
    "But if you put them in array\n",
    "\n",
    "    B[] array_b = new A[1];  \n",
    "    \n",
    "    array_b[0] = new B();     // this passes the compiler but at runtime throw ArrayStoreException\n",
    "    \n",
    "    //what one should do is\n",
    "    \n",
    "    array_b[0] = new A(); \n",
    "    \n",
    "    //or\n",
    "    \n",
    "    array_b[0] = (B)new A(); \n",
    "\n",
    "\n",
    "The wildcards make compiler aware the problems\n",
    "    \n",
    "    ArrayList<? extends B> list_b = new ArrayList<A>();\n",
    "    \n",
    "    ArrayList<? super A> list_a = new ArrayList<B>();\n",
    "    \n",
    "\n",
    "In this way, the compiler can check the type and will not pass the check. Because\n",
    "\n",
    "now the compiler knows \n",
    "    \n",
    "\n",
    "    elements of list_b are sub class of B, hence any method of any sub class of B\n",
    "    \n",
    "including B itself can be safely invoked on elements of list_b\n",
    "\n",
    "\n",
    "    elements of list_a are super class of A, hence any super class of A including A itself \n",
    "    \n",
    "can be safely casted into list_a. \n",
    "\n",
    "\n",
    "so unlike before\n",
    "\n",
    "    list_b.add(new B()); // will not pass the compiler. In fact the compiler won't allow to add anything\n",
    "    \n",
    "    // the legitimate way is to copy\n",
    "    \n",
    "    // first create something\n",
    "    ArrayList<A> someList = new ArrayList<A>();\n",
    "    someList.add(new A());\n",
    "        \n",
    "    // then\n",
    "    ArrayList<? extends B> list_b = new ArrayList<A>(someList);\n",
    "    list_b.get(0) //this is actually object A, not the upcasted A\n",
    "\n",
    "    //For the super list\n",
    "    ArrayList<? super A> list_a = new ArrayList<B>();\n",
    "    list_a.add(new A());\n",
    "    \n",
    "    // or\n",
    "    \n",
    "    \n",
    "*/\n",
    "\n",
    "// In Scala  putting + / - , otherwise it is invariant\n",
    "    \n",
    "\n",
    "class Covariance_List[+T]{}\n",
    "class Controvariace_List[-T]{} \n",
    "\n",
    "class B {}\n",
    "class A extends B {} \n",
    "\n",
    "object main extends App{\n",
    "    val list_B : Covariance_List[B] = new Covariance_List[A] \n",
    "    val list_A : Controvariace_List[A] = new Controvariace_List[B]  \n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "With the use of Covariance, Invariance and Contravariance\n",
    "\n",
    "One needs to know the Type Hierarchy<br>\n",
    "Ref http://docs.scala-lang.org/tutorials/tour/unified-types.html\n",
    "![](http://docs.scala-lang.org/resources/images/classhierarchy.img_assist_custom.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='collect'></a>\n",
    "## Collections\n",
    "\n",
    "Immutable Collection\n",
    "![](http://docs.scala-lang.org/resources/images/collections.immutable.png)\n",
    "<br>\n",
    "Mutable Collection\n",
    "![](http://docs.scala-lang.org/resources/images/collections.mutable.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "List(1, 2)\n",
      "1\n",
      "List(1, 2, 3, 4, 5, 6)\n",
      "List(List(4, 5, 6), 1, 2, 3)\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// List, Immutable\n",
    "//\n",
    "\n",
    "val list1 = List(1,2,3)\n",
    "val list2 = List(4,5,6) \n",
    "println(list1.length)\n",
    "println(list1.take(2))\n",
    "println(list1(0))\n",
    "\n",
    "//same as list1 ++ list2, \n",
    "println(list1 ::: list2)\n",
    "\n",
    "//:: is the append method in List1, with three ::: another : reverse the operands\n",
    "println(list1.::( list2) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(1, 2, 3, 4, 5, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// impletment concatenation\n",
    "\n",
    "def concat[T](xs: List[T], ys: List[T]): List[T] = xs match {\n",
    "    case List() => ys\n",
    "    case z :: zs => z :: concat(zs, ys)    \n",
    "}\n",
    "\n",
    "concat(list1, list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(1, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// implement removeAt\n",
    "\n",
    "def removeAt[T](n: Int, x: List[T]) = {\n",
    "    (x take n) ::: (x drop n+1)\n",
    "}\n",
    "\n",
    "removeAt(1, list1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(1, 5, 10, 15, 30)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// insertion sort\n",
    "\n",
    "\n",
    "def isort(xs: List[Int]): List[Int] = xs match {\n",
    "    case List() => List()\n",
    "    case y :: ys => {\n",
    "        def insert(x1: Int, xs1: List[Int]): List[Int] = xs1 match {\n",
    "            case List() => List(x1)\n",
    "            case y1 :: ys1 => if (x1 < y1) x1 :: xs1 else y1 :: insert(x1, ys1)\n",
    "        }\n",
    "        insert(y, isort(ys))\n",
    "    }\n",
    "}\n",
    "\n",
    "isort(List(5, 30, 10, 1, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(1, 5, 10, 15, 30)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// merge sort\n",
    "//\n",
    " \n",
    "def msort(xs: List[Int]) : List[Int] = {\n",
    "\n",
    "    val n = xs.length / 2\n",
    "    if (n==0) xs\n",
    "    else {\n",
    "        def merge(xs: List[Int], ys: List[Int]): List[Int] = (xs, ys) match {\n",
    "            case (Nil, ys) => ys\n",
    "            case (xs, Nil) => xs\n",
    "            case (x :: xs1, y:: ys1) => { \n",
    "                \n",
    "                if (x < y) x :: merge(xs1, ys)\n",
    "                else y :: merge(xs, ys1)\n",
    "            }\n",
    "             \n",
    "        } \n",
    "        val (fst , snd ) = xs splitAt n\n",
    "        merge(msort(fst), msort(snd))\n",
    "    }\n",
    "}\n",
    "\n",
    "msort(List(5, 30, 10, 1, 15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(1, 5, 10, 15, 30)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// merge sort with type parameter, user-defined comparison\n",
    "\n",
    "\n",
    "def msort[T](xs: List[T])(lt: (T,T) => Boolean) : List[T] = {\n",
    "\n",
    "        val n = xs.length / 2\n",
    "        if (n==0) xs\n",
    "        else {\n",
    "            def merge(xs: List[T], ys: List[T]): List[T] = (xs, ys) match {\n",
    "                case (Nil, y :: ys1) => ys\n",
    "                case (x :: xs1, Nil) => xs\n",
    "                case (x :: xs1, y:: ys1) => {\n",
    "\n",
    "                    if (lt(x,y)) x :: merge(xs1, ys)\n",
    "                    else y :: merge(xs, ys1)\n",
    "                }\n",
    "\n",
    "            }\n",
    "\n",
    "            val (fst , snd ) = xs splitAt n\n",
    "            merge(msort(fst)(lt), msort(snd)(lt))\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "msort(List(5, 30, 10, 1, 15))((x, y) => x < y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(1, 5, 10, 15, 30)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// merge sort with type parameter, default ordering comparison\n",
    "// adding implicit and ask compiler to fill in the missing part\n",
    "\n",
    "import math.Ordering \n",
    "\n",
    "def msort[T](xs: List[T])(implicit ord: Ordering[T]) : List[T] = {\n",
    "\n",
    "    val n = xs.length / 2\n",
    "    if (n==0) xs\n",
    "    else {\n",
    "        def merge(xs: List[T], ys: List[T]) : List[T] = (xs, ys) match {\n",
    "            case (Nil, y :: ys1) => ys\n",
    "            case (x :: xs1, Nil) => xs\n",
    "            case (x :: xs1, y:: ys1) => {\n",
    "\n",
    "                if (ord.lt(x,y)) x :: merge(xs1, ys)\n",
    "                else y :: merge(xs, ys1)\n",
    "            }\n",
    "\n",
    "        }\n",
    "\n",
    "        val (fst , snd ) = xs splitAt n\n",
    "        merge(msort(fst), msort(snd)) \n",
    "        //merge(msort(fst)(ord), msort(snd)(ord)) \n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "//without implicit, we need to\n",
    "//msort(List(5, 30, 10, 1, 15))(Ordering.Int) \n",
    "\n",
    "msort(List(5, 30, 10, 1, 15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(5, 15, 25, 10, 20)\n",
      "List(3, 9, 15, 6, 12)\n",
      "List(1, 2)\n",
      "List(3, 5, 4)\n",
      "(List(1, 2),List(3, 5, 4))\n",
      "List(1)\n",
      "List(3, 5, 2, 4)\n",
      "(List(1),List(3, 5, 2, 4))\n"
     ]
    }
   ],
   "source": [
    "//  functions on list, using map, filter ... (called transformers)\n",
    "// Later we will talk about transformation vs action in spark\n",
    "// using them wisely is important, because we don't want to write any loops.\n",
    "\n",
    "\n",
    "def rescale(xs: List[Int], factor :Int) = {\n",
    "    xs map (x => x * factor)   //Scala map is tail-recursive\n",
    "}\n",
    "\n",
    "val l = List(1, 3, 5, 2, 4)\n",
    "println(rescale(l, 5))\n",
    "\n",
    "// or\n",
    "\n",
    "println(l map (x => x * 3)) \n",
    "\n",
    "println(l filter (x => x < 3))\n",
    "println(l filterNot (x => x < 3))\n",
    "println(l partition (x => x <3))  //partition around filter and fitlerNot\n",
    "  \n",
    "\n",
    "println(l takeWhile (x => x< 3))  // take the prefix of the list up the criteria \n",
    "println(l dropWhile (x => x< 3)) \n",
    "println(l span (x => x< 3))       // combine takeWhile and dropWhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List((a,3), (b,2), (c,1), (a,1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// implement encode. No loops\n",
    "\n",
    "def encode [T](xs: List[T]) = {\n",
    "\n",
    "        def pack(ls: List[T]) : List[List[T]] =  ls match{\n",
    "\n",
    "            case List() => List()\n",
    "            case x :: xs1 => {\n",
    "                val (fst, scn) = ls span (y => y == x)\n",
    "                fst :: pack(scn)\n",
    "            }\n",
    "        }\n",
    "        pack(xs) map ( x => (x.head, x.length))\n",
    "    }\n",
    "\n",
    " \n",
    "\n",
    "val data = List(\"a\", \"a\", \"a\", \"b\", \"b\", \"c\", \"a\")\n",
    "\n",
    "encode(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// reduceLeft applies operation to the left of the element \n",
    "// so below is the same as, but it will be tail-recursive, using foldLeft\n",
    "//      \n",
    "//     (( 1 + 2 ) + 3 ) +4\n",
    "//\n",
    "List(1,2,3,4).reduceLeft( _ + _ ) //  _ + _  is the same as (x, y) => x + y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// reduceRight applies operation to the right of the element \n",
    "// so below is the same as\n",
    "//      \n",
    "//    1 + ( 2 + ( 3 + 4 ) )\n",
    "//\n",
    "List(1,2,3,4).reduceRight( _ + _ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "// foldLeft\n",
    "\n",
    "val z = 0\n",
    "\n",
    "println((List(1,2,3,4) foldLeft z )( _ + _ )) \n",
    "\n",
    "//tail-recursive, using z as initial accumulator, but the value of z doesn't change\n",
    "\n",
    "println(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(pear, apple, banana, pineapple)\n",
      "List(apple, banana, pear, pineapple)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "// List has sorted \n",
    "\n",
    "val fruit = List(\"apple\",\"pineapple\", \"pear\", \"banana\")\n",
    "\n",
    "println(fruit sortWith(_.length < _.length))\n",
    "println(fruit sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// iterable\n",
    "//   sequence\n",
    "//     List -> linked list\n",
    "//     Vectors -> very shallow tree, node has 32 children \n",
    "//     array\n",
    "//     string\n",
    "//     range\n",
    "//   set \n",
    "//   map\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// example dot product\n",
    "\n",
    "val v1 = Vector(1,2,3,4,5)\n",
    "val v2 = Vector(1,2,3,4,5)\n",
    "\n",
    "def dotProd(v1: Vector[Int], v2: Vector[Int]) = {\n",
    "    (v1 zip v2).map(xy => xy._1 * xy._2).sum \n",
    "}\n",
    "\n",
    "dotProd(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// range is seq\n",
    "\n",
    "def isPrime(n: Int)  = (2 until n) forall (d => n%d != 0)\n",
    "\n",
    "isPrime(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector((1,1), (1,2), (1,3), (2,1), (2,2), (2,3), (3,1), (3,2), (3,3))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// double loops in scala\n",
    "\n",
    "((1 until 4) map (i => (1 until 4 ) map (j => (i,j)))).flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector((1,1), (1,2), (1,3), (2,1), (2,2), (2,3), (3,1), (3,2), (3,3))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// or \n",
    "\n",
    "(1 until 4) flatMap (i => (1 until 4 ) map (j => (i,j)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector((2,1), (3,2))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// simplier way is to use For\n",
    "\n",
    "// For\n",
    "\n",
    "// find pairs summing to a prime\n",
    " \n",
    "for {                 //use curly bracket save commas\n",
    "    i <- 1 until 4    //generator\n",
    "    j <- 1 until i    \n",
    "    if isPrime(i+j)   //filter i, j \n",
    "} yield (i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Vector((2,1), (3,2))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// same as above, but much convoluted\n",
    "\n",
    "                                        //  the case is pattern matching, \n",
    "                                        //   the full expression is  filter (e=>e match { case ...\n",
    "(1 until 4) flatMap (i => (1 until i ) map (j => (i,j))) filter ( {case (x,y)=> isPrime(x+y)} )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// rewrit dot product using For\n",
    "\n",
    "val v1 = Vector(1,2,3,4,5)\n",
    "val v2 = Vector(1,2,3,4,5)\n",
    "\n",
    "def dotProd(v1: Vector[Int], v2: Vector[Int]) = {\n",
    "    (for ( (i,j) <- (v1 zip v2)) yield i*j).sum\n",
    "}\n",
    "\n",
    "dotProd(v1, v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n",
      "\n",
      "\n",
      "* * * * * X * * \n",
      "* * * X * * * * \n",
      "* X * * * * * * \n",
      "* * * * * * * X \n",
      "* * * * X * * * \n",
      "* * * * * * X * \n",
      "X * * * * * * * \n",
      "* * X * * * * * \n",
      "\n",
      "* * * * X * * * \n",
      "* * * * * * X * \n",
      "* X * * * * * * \n",
      "* * * X * * * * \n",
      "* * * * * * * X \n",
      "X * * * * * * * \n",
      "* * X * * * * * \n",
      "* * * * * X * * \n",
      "\n",
      "* * * * * X * * \n",
      "* * X * * * * * \n",
      "* * * * * * X * \n",
      "* * * X * * * * \n",
      "X * * * * * * * \n",
      "* * * * * * * X \n",
      "* X * * * * * * \n",
      "* * * * X * * * "
     ]
    },
    {
     "data": {
      "text/plain": [
       "Set(())"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "//\n",
    "// Set not seq, unorder, no duplicate\n",
    "//\n",
    "\n",
    "// 8-queens\n",
    "\n",
    "// the following codes are copied from Martin Odersky course\n",
    "// Compare it to my code http://nbviewer.jupyter.org/github/ronnnwu/codetheInterviewExercises/blob/master/Ch8.ipynb\n",
    "// problem 8.12 \n",
    "\n",
    "// Scala immutable List makes recursion very natural and the high-order list function, \n",
    "// for iterator really helped too\n",
    "\n",
    "// In python I had to make copies and write loops over loops. Scala is faster too.\n",
    "\n",
    "def queens(n: Int) : Set[List[Int]] ={ \n",
    "    \n",
    "    //place queen at row k\n",
    "    def placeQueens(k: Int) : Set[List[Int]] = {\n",
    "        if (k==0) Set(List())\n",
    "        else {\n",
    "            for {\n",
    "                queens <- placeQueens(k-1)\n",
    "                col <- 0 until n\n",
    "                if isSafe(col, queens)\n",
    "\n",
    "            } yield col :: queens  \n",
    "            //output e.g. List(1,5,3) means queens at row 0 col 3, row 1 col 5, row 2 col 1 \n",
    "            //hence as k increases it appends queens to the front\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    def isSafe(col: Int, queens: List[Int]): Boolean = {\n",
    "        val row  = queens.length\n",
    "        // decode queens row and col and rows are in reverse order\n",
    "        val queensWithRow = (row - 1 to 0 by -1) zip queens\n",
    "        queensWithRow forall {\n",
    "            case (r,c) => col != c && math.abs(col-c) != row - r // check no col used, no diagonal match\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    placeQueens(n)\n",
    "}\n",
    "\n",
    " \n",
    "println(queens(8).size) \n",
    "\n",
    "def prettyShow(queens: List[Int]) = {\n",
    "    val lines = {\n",
    "        for (col <- queens.reverse)\n",
    "            yield Vector.fill(queens.length)(\"* \").updated(col, \"X \").mkString\n",
    "\n",
    "    }\n",
    "    print(\"\\n\\n\" + (lines mkString \"\\n\"))\n",
    "}\n",
    "\n",
    "queens(8) take 3 map prettyShow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some(DC)\n",
      "Map(US -> NYC, France -> Paris)\n",
      "Map(US -> NYC, France -> Paris)\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// Map\n",
    "//\n",
    "\n",
    "val Capital = Map(\"US\"->\"DC\", \"France\"->\"Paris\")\n",
    "\n",
    "println(Capital get \"US\")\n",
    "\n",
    "println(Capital + (\"US\"->\"NYC\")) \n",
    "\n",
    "// + map will replace value which is same as\n",
    "\n",
    "println(Capital ++ Map(\"US\"->\"NYC\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map(5 -> List(apple), 9 -> List(pineapple), 6 -> List(orange, banana))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "// List has groupBy\n",
    "// returns a Map\n",
    "\n",
    "val fruit = List(\"apple\",\"pineapple\", \"orange\", \"banana\")\n",
    "\n",
    "fruit groupBy(_.length)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3 * x ^ 3 + 2.2 * x ^ 2 + 2.2 * x ^ 1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// example polynomial class\n",
    "\n",
    "                              // deg, coeff\n",
    "class Poly (val terms0: Map[Int, Double])  {\n",
    "    \n",
    "    val terms = terms0 withDefaultValue 0.0  //this allows terms(deg) in addTerm to return 0\n",
    "    \n",
    "    def + (other: Poly) = new Poly((other.terms foldLeft terms)(addTerm))\n",
    "    \n",
    "    def addTerm(terms: Map[Int,Double], term: (Int, Double)) = {\n",
    "        val (deg, coeff) = term\n",
    "        terms + (deg -> (coeff + terms(deg))) //use terms as initial accumulator and update its value\n",
    "    }\n",
    "    override def toString =\n",
    "        (for ( (deg, ceof)<- terms.toList.sorted.reverse )\n",
    "            yield ceof + \" * x ^ \" + deg) mkString(\" + \")\n",
    "}\n",
    "\n",
    "val p1 = new Poly(Map(1->1.1, 2->2.2))\n",
    "val p2 = new Poly(Map(1->1.1, 3->3.3))\n",
    "\n",
    "p1 + p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3*x^3+2.2*x^2+2.2*x^1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// an improved version\n",
    "\n",
    "class Poly (val terms0: Map[Int, Double])  {\n",
    "    \n",
    "    // another constructor will take a squence of (Int,Double) unspecified size\n",
    "    // and pass to the default constructor\n",
    "    def this(bindings: (Int, Double)*) = this(bindings.toMap)\n",
    "    \n",
    "    val terms = terms0 withDefaultValue 0.0\n",
    "\n",
    "    def + (other: Poly) = new Poly((other.terms foldLeft terms)(addTerm))\n",
    "    def addTerm(terms: Map[Int,Double], term: (Int, Double)) = {\n",
    "        val (deg, coeff) = term\n",
    "        terms + (deg -> (coeff + terms(deg)))\n",
    "    }\n",
    "    override def toString =\n",
    "        (for ( (deg, ceof)<- terms.toList.sorted.reverse )\n",
    "            yield ceof + \"*x^\" + deg) mkString(\"+\")\n",
    "}\n",
    "\n",
    "val p1 = new Poly(1->1.1, 2->2.2)\n",
    "val p2 = new Poly(1->1.1, 3->3.3)\n",
    "\n",
    "p1 + p2\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45382\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Set(sack air fun, pack ah re to, pack bird to, Scala ire to, Scala is fun, rack ah re to, pack air fun, sack bird to, rack bird to, sack ah re to, rack air fun)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//example of translating a sequence of number to a sentence\n",
    "\n",
    "import scala.io.Source\n",
    "\n",
    "val in = Source.fromURL(\"http://lamp.epfl.ch/files/content/sites/lamp/files/teaching/progfun/linuxwords.txt\")\n",
    "\n",
    "//get common English words, drop hyphenated words, symbols etc\n",
    "val words = in.getLines.toList filter (word => word forall (chr => chr.isLetter)) \n",
    "println(words.length)   //  45382 words\n",
    "\n",
    "// telephone keypad\n",
    "val mnem = Map('2' -> \"ABC\", '3' -> \"DEF\", '4' -> \"GHI\",'5' -> \"JKL\",\n",
    "    '6' -> \"MNO\", '7' -> \"PQRS\", '8' -> \"TUV\", '9' -> \"WXYZ\")\n",
    "\n",
    "// reverse Map of mnem\n",
    "val charCode: Map[Char, Char] =  for ((digit, str) <- mnem; ltr <- str) yield (ltr -> digit)\n",
    "\n",
    "// the groupBy will return a map from numbers to all 45382 words\n",
    "val wordsForNum: Map[String, List[String]] = {\n",
    "    \n",
    "    def wordCode(word: String) =  word.toUpperCase map charCode\n",
    "    words groupBy wordCode withDefaultValue List()  //not found default is an empty List()\n",
    "}\n",
    "\n",
    "def encode(number: String): Set[List[String]] = {\n",
    "    if (number.isEmpty) Set(List())\n",
    "    else {\n",
    "        for {\n",
    "            split <- 1 to number.length\n",
    "            word <- wordsForNum(number take split)  \n",
    "            // if wordsForNum return an empty List, the iterator is Nil \n",
    "            // so that that iteration is skipped\n",
    "            \n",
    "            rest <- encode(number drop split) //the iterator is an element of the set hence a List\n",
    "        } yield word :: rest // a string of a word concat to a list\n",
    "    }.toSet\n",
    "}\n",
    "\n",
    "\n",
    "def translate(number: String): Set[String] =\n",
    "    encode(number) map ( _ mkString \" \" )\n",
    "\n",
    "translate(\"7225247386\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'funDe'></a>\n",
    "## Functional Design in Scala\n",
    "\n",
    "Codes in this section are mostly copied from Martin Odersky course on coursera https://www.coursera.org/learn/progfun2/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='for'></a>\n",
    "### For Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"firstName\": \"John\", \"lastName\": \"Smith\", \"address\": {\"streeAddress\": \"21 2nd Street\", \"state\": \"NY\", \"postslCode\": 10021}, \"phoneNumer\": [{\"type\": \"home\", \"number\": \"212 344 1345\"}, {\"type\": \"cell\", \"number\": \"212 542 1345\"}]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Scala with JSON\n",
    "\n",
    "/*\n",
    "    run this cell only once \n",
    "*/\n",
    "\n",
    "abstract class JSON\n",
    "case class JSeq(elem: List[JSON]) extends JSON\n",
    "case class JObj(bingdings: Map[String, JSON]) extends JSON\n",
    "case class JNum(num: Int) extends JSON\n",
    "case class JStr(str: String) extends JSON\n",
    "case class JBool(b: Boolean) extends JSON\n",
    "case object JNull extends JSON\n",
    "\n",
    "val data = JObj(Map(\n",
    "    \"firstName\" -> JStr(\"John\"),\n",
    "    \"lastName\"->JStr(\"Smith\"),\n",
    "    \"address\"->JObj(Map(\n",
    "        \"streeAddress\"->JStr(\"21 2nd Street\"),\n",
    "        \"state\"->JStr(\"NY\"),\n",
    "        \"postslCode\"->JNum(10021)\n",
    "    )),\n",
    "    \"phoneNumer\"->JSeq(List(\n",
    "        JObj(Map(\n",
    "            \"type\"->JStr(\"home\"),\n",
    "            \"number\"->JStr(\"212 344 1345\")\n",
    "        )),\n",
    "        JObj(Map(\n",
    "            \"type\"->JStr(\"cell\"),\n",
    "            \"number\"->JStr(\"212 542 1345\")\n",
    "        ))\n",
    "    ))\n",
    "))\n",
    "\n",
    "def prettyJSON(json: JSON) : String = json match {\n",
    "    case JSeq(elem) =>\n",
    "        \"[\" + (elem map prettyJSON mkString \", \") + \"]\"\n",
    "    case JObj(bindings) =>\n",
    "        val assoc = bindings map {\n",
    "            case (key, value) => \"\\\"\" + key + \"\\\": \" + prettyJSON(value)\n",
    "        }\n",
    "        \"{\" + (assoc mkString \", \") + \"}\"\n",
    "    case JNum(num) => num.toString\n",
    "    case JStr(str) => \"\\\"\" + str + \"\\\"\"\n",
    "    case JBool(b) => b.toString\n",
    "    case JNull => \"Null\"\n",
    "}\n",
    "\n",
    "prettyJSON(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List((JStr(John),JStr(Smith),212 344 1345))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// use For as select for JSON\n",
    "// same idea as Linq in C#\n",
    "\n",
    "val data_collect = List(data) // suppose we have more than one piece of data\n",
    "\n",
    "    for {\n",
    "        JObj(bindings) <- data_collect\n",
    "        JSeq(phones) = bindings(\"phoneNumer\")\n",
    "        JObj(phone) <- phones\n",
    "        JStr(digits) = phone(\"number\")\n",
    "        if digits contains \"344\"\n",
    "    } yield (bindings(\"firstName\"), bindings(\"lastName\"), digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Set(J. K. Rowling)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// For for NoSql\n",
    "\n",
    "case class Book(title: String, author: String)\n",
    "\n",
    "val books: Set[Book] =  Set(  \n",
    "\n",
    "    //using set will avoid not only duplicated items, but also duplicated selections\n",
    "    \n",
    "    Book( \"Harry Potter and the Deathly Hallows\", \"J. K. Rowling\"),\n",
    "    Book( \"Harry Potter and the Philosopher's Stone\", \"J. K. Rowling\"), \n",
    "    Book( \"Harry Potter And The Cursed Child\", \"J. K. Rowling\"),  \n",
    "    Book( \"Angels & Demons\", \"Dan Brown\"),\n",
    "    Book( \"The Audacity of Hope\", \"Barack Obama\")\n",
    ")\n",
    "\n",
    "\n",
    "for {\n",
    "    b1 <- books\n",
    "    b2 <- books\n",
    "    if b1.title < b2.title\n",
    "    if b1.author == b2.author  //author has more than 1 book\n",
    "} yield  b1.author\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1855451955\n",
      "false\n",
      "(false,false)\n"
     ]
    }
   ],
   "source": [
    "// For as random generator\n",
    "\n",
    "trait Generator[+T] {\n",
    "    self =>\n",
    "    def generate: T\n",
    "\n",
    "    //handmade map to trick For-expression \n",
    "    def map[S](f: T => S): Generator[S] = new Generator[S] {\n",
    "        def generate = f(self.generate)\n",
    "    }\n",
    "\n",
    "    def flatMap[S](f: T => Generator[S]): Generator[S] = new Generator[S] {\n",
    "        def generate = f(self.generate).generate\n",
    "    }\n",
    "}\n",
    "\n",
    "val integers = new Generator[Int] {\n",
    "    val ran = new java.util.Random\n",
    "    def generate = ran.nextInt()\n",
    "}\n",
    "println(integers.generate)\n",
    "\n",
    "//for other types, .nextBoolean(), \n",
    "//val booleans = new Generator[ Boolean] {\n",
    "//    def generate = integers.generate > 0\n",
    "//}\n",
    "\n",
    "// or\n",
    "val booleans = for( x <- integers) yield (x > 0)\n",
    "\n",
    "//that is because\n",
    "//\n",
    "// for ( x <- e1 ) yield e2\n",
    "//\n",
    "// is actually\n",
    "//\n",
    "//     e1.map(x => e2)\n",
    "//\n",
    "// which translates to\n",
    "//\n",
    "//     val booleans = integers.map(_>0)\n",
    "//\n",
    "println(booleans.generate)\n",
    "\n",
    "\n",
    "def pair[U,V](u: Generator[U], v: Generator[V]) = for {\n",
    "    x <- u\n",
    "    y <- v\n",
    "} yield (x,y)\n",
    "\n",
    "//that is because\n",
    "//\n",
    "// for {\n",
    "//      x <- e1\n",
    "//      y <- e2\n",
    "// } yield e3\n",
    "//\n",
    "// is actually\n",
    "//\n",
    "//     e1.flatMap(x => ( e2.map( y => e3)) )\n",
    "//\n",
    "// which translates to\n",
    "//\n",
    "//     def pair[U,V](u: Generator[U], v: Generator[V]) = for {\n",
    "//             u flatMap (x => v map ( y => (x,y) )\n",
    "//\n",
    "println(pair(booleans, booleans).generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// get random number from 1 upto 9\n",
    "\n",
    "def choose(lo: Int, hi: Int) : Generator[Int] =\n",
    "        for (x <- integers) yield lo + (math.abs(x)%(hi - lo))\n",
    "\n",
    "choose(1, 10).generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "c"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// return a random element\n",
    "\n",
    "def oneOf[T](xs: T*): Generator[T] ={\n",
    "        for (idx <- choose (0, xs.length)) yield xs(idx)\n",
    "    }\n",
    "\n",
    "oneOf(\"a\",\"b\",\"c\",\"d\",\"e\",\"f\",\"g\").generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// random list of arbitrary length\n",
    "\n",
    "def lists: Generator[List[Int]] = {\n",
    "    \n",
    "    def single[T] (x: T)  = new Generator[T] {\n",
    "        def generate = x\n",
    "    }\n",
    "\n",
    "    def nonEmptyList = for {\n",
    "        head <- choose(1, 11)\n",
    "        tail <- lists\n",
    "    } yield head :: tail\n",
    "    \n",
    "    for {\n",
    "        isEmpty <- choose(1, 11)\n",
    "        list <- if (isEmpty >= 10) single(Nil) else nonEmptyList\n",
    "        //need to put Nil in wrap because the generate call will be called on it\n",
    "    } yield list\n",
    "\n",
    "}\n",
    "\n",
    "lists.generate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name='stream'></a>\n",
    "### Stream & Lazy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Range(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// Stream same as List, but only create them fully when someone evaluates it\n",
    "\n",
    "(1 to 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stream(1, ?)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1 to 100).toStream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zxxy"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// lazy means store results from last evaluation.\n",
    "// let us compare call-by-name(def), call-by-value(val), and lazy\n",
    "\n",
    "def expr = {\n",
    "    def x = { print(\"x\"); 1 }  // this is evaluated when it is called\n",
    "    \n",
    "    lazy val y = { print(\"y\"); 1 } //this will not be evaluted until it is called, \n",
    "                                   //After it is called, it will not be called again, the value is stored\n",
    "\n",
    "    val z = { print(\"z\") ; 1 }  // this is evaluated when the program goes through this line \n",
    "                                // and the value is stored\n",
    "\n",
    "    x + x + y + y + z + z   //this is evaluated from left to right\n",
    "}\n",
    "\n",
    "expr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229, 233, 239, 241, 251, 257, 263, 269, 271, 277, 281, 283, 293, 307, 311, 313, 317, 331, 337, 347, 349, 353, 359, 367, 373, 379, 383, 389, 397, 401, 409, 419, 421, 431, 433, 439, 443, 449, 457, 461, 463, 467, 479, 487, 491, 499, 503, 509, 521, 523, 541)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//with Stream one can play with an infinite list\n",
    "\n",
    "//this creates an infinite Stream\n",
    "def from(n: Int) : Stream[Int] = n #:: from(n+1)\n",
    "\n",
    "// #:: is for stream concat\n",
    "def sieve(s: Stream[Int]): Stream[Int] =\n",
    "    s.head #:: sieve(s.tail filter ( _ % s.head != 0)) //filter out any multiple of primes\n",
    "\n",
    "val primes = sieve(from(2))\n",
    "\n",
    "//this returns the first 100 primes\n",
    "primes.take(100).toList  //Stream take method will only creates list up to the first 100th primes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(2.0000000929222947)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// for convergence problem, we no longer have to worry if the sequence is infinite or not\n",
    "\n",
    "def sqrtStream(x : Double) : Stream[Double] = {\n",
    "    def improve (guess: Double) = (guess + x / guess) / 2\n",
    "    lazy val guesses: Stream[Double] = 1 #:: (guesses map improve) \n",
    "    guesses\n",
    "}\n",
    "def isGoodEnough(x: Double, n: Double)={\n",
    "    math.abs(x*x-n) < 0.0001\n",
    "}\n",
    "sqrtStream(4).filter(x=>isGoodEnough(x,4)).take(1).toList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "List(Fill(0) Pour(0,1) Fill(0) Pour(0,2) Fill(0) Pour(0,2) Pour(2,1) --> Vector(0, 5, 7))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// N Water jugs problems \n",
    "//\n",
    "//\n",
    "class Pouring(capacity: Vector[Int]){  //capacity is the max amount of water each glass can take \n",
    "    \n",
    "    val glasses = 0 until capacity.length //label glasses 0 to n-1\n",
    " \n",
    "    type State = Vector[Int] \n",
    "    val initialState = capacity map ( x => 0)  //create a new Vector with all zeros\n",
    "   \n",
    "    //total possbile moves\n",
    "    val moves =\n",
    "        (for (g <- glasses) yield Empty(g)) ++\n",
    "        (for (g <- glasses) yield Fill(g)) ++\n",
    "        (for (from <- glasses; to <- glasses if from != to) yield Pour(from, to))\n",
    "\n",
    " \n",
    "    trait Move {\n",
    "        def change(state: State) : State //state: amount of water in each glass\n",
    "    }\n",
    "    case class Empty(glass: Int) extends Move{\n",
    "        def change(state: State)  =  state updated (glass, 0)\n",
    "    }\n",
    "    case class Fill(glass: Int) extends Move{\n",
    "        def change(state: State)  =  state updated (glass, capacity(glass))\n",
    "    }\n",
    "    case class Pour(from: Int, to : Int) extends Move{\n",
    "        def change(state: State)  = {\n",
    "            val amount = state(from) min (capacity(to) - state(to))\n",
    "            state updated(from, state(from) - amount) updated(to, state(to) + amount)\n",
    "        }\n",
    "    }\n",
    "\n",
    "      \n",
    "    class Path(history: List[Move], val endState: State){\n",
    "        //def endState: State = trackState(history)\n",
    "        //private def trackState(xs: List[Move]) : State = xs match {\n",
    "        //    case Nil => initialState\n",
    "        //    case move :: xs1 => move change trackState(xs1)\n",
    "        //}\n",
    "\n",
    "        //accomplished the same as above\n",
    "        //def endState: State = (history foldRight initialState) ( _ change _ )\n",
    "\n",
    "        //or avoid recursive compute endState, update the endState when new moves are added\n",
    "        //new moves are added in front\n",
    "        def extend(move: Move) = new Path(move::history, move change endState)\n",
    "        \n",
    "        override def toString = (history.reverse mkString \" \" ) + \" --> \" + endState\n",
    "    }\n",
    "\n",
    "    val initialPath = new Path(Nil, initialState)\n",
    "\n",
    "    def from(paths: Set[Path], explored: Set[State]): Stream[Set[Path]] =\n",
    "        if (paths.isEmpty) Stream.empty\n",
    "        else {\n",
    "            val more = for {\n",
    "                path <- paths\n",
    "                next <- moves map path.extend  //this will add the every possible move to all pathes\n",
    "                if !(explored contains next.endState) //if the final state has been reached, it will skip\n",
    "            } yield next\n",
    "            paths #:: from(more, explored ++ (more map (_.endState))) //generating pathes, an infinite list of set\n",
    "        }                                                             \n",
    "\n",
    "    val pathSets = from(Set(initialPath), Set(initialState)) \n",
    "\n",
    "    def solution (target: Int) : Stream[Path] =\n",
    "        for {\n",
    "            pathSet <- pathSets   //and thanks Stream in from method, it will only create path when it needs to\n",
    "            path <- pathSet\n",
    "            if path.endState contains target\n",
    "        } yield path\n",
    "}\n",
    "\n",
    "\n",
    "// any number of glasses.\n",
    "// specify the desired amount to be in any one of the glasses\n",
    "val problem = new Pouring(Vector(4, 5, 9))\n",
    "problem.solution(7).take(1).toList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name='event'></a>\n",
    "### Event Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/*\n",
    "    the follow codes cannot run in the cell. It has to save and compile in files.\n",
    "    \n",
    "    \n",
    "    It contains 4 classes and 1 test unit. It would be better to save them in 5 separated files\n",
    "    \n",
    "    The program simulates a digital halfAdder comprised by inverter, andGate, orGate\n",
    "    \n",
    "    and produces\n",
    "    \n",
    "    \n",
    "            At time = 0, sum wire = 0\n",
    "            At time = 0, carry wire = 0\n",
    "            *** Simulation started, time = 0 ***\n",
    "            At time = 2, sum wire = 1\n",
    "            *** Simulation started, time = 2 ***\n",
    "            At time = 3, carry wire = 1\n",
    "            At time = 5, sum wire = 0\n",
    "            *** Simulation started, time = 5 ***\n",
    "            At time = 6, carry wire = 0\n",
    "            At time = 8, sum wire = 1\n",
    " \n",
    "\n",
    "*/\n",
    "\n",
    "\n",
    "abstract class Simulation {\n",
    "    type Action = () => Unit\n",
    "\n",
    "    case class Event(time: Int, action: Action) //logging\n",
    "\n",
    "    private var curTime = 0\n",
    "    def currentTime: Int = curTime //time getter\n",
    "\n",
    "    private var agenda : List[Event] = List()\n",
    "\n",
    "    private def insert(ag: List[Event], item: Event) : List[Event] = ag match{\n",
    "        //insert event based on time, later event add to the end\n",
    "        case first:: rest if first.time <= item.time =>\n",
    "            first :: insert(rest, item)\n",
    "        case _ =>\n",
    "            item :: ag\n",
    "    }\n",
    "\n",
    "    def afterDelay(delay: Int)(block : => Unit): Unit = {\n",
    "        //as signal passing through each gate, events will be logged\n",
    "        //the delay creates a time stamp. \n",
    "        //Without it, outputs will change instantaneously, thus it helps to simulate the signal \n",
    "        //more realistically. \n",
    "        //From the time stamps one can create electrical signal graph like in an oscilloscope\n",
    "        val item = Event(curTime + delay, () => block)\n",
    "        agenda = insert (agenda, item)\n",
    "    }\n",
    "    def run(): Unit = {\n",
    "        afterDelay(0){\n",
    "            println(\"*** Simulation started, time = \" + currentTime + \" ***\")\n",
    "        }\n",
    "        loop() //run everything in the log\n",
    "    }\n",
    "    private def loop(): Unit = agenda match {\n",
    "        case first :: rest =>\n",
    "            agenda = rest\n",
    "            curTime = first.time\n",
    "            first.action()\n",
    "            loop()\n",
    "        case Nil =>\n",
    "    }\n",
    "}\n",
    "\n",
    "trait Parameters{\n",
    "\n",
    "    def InverterDelay = 1  // delay time in seconds\n",
    "    def AndGateDelay = 1\n",
    "    def OrGateDelay = 1\n",
    "}\n",
    "\n",
    "abstract class Gates extends Simulation{\n",
    "\n",
    "    def InverterDelay : Int\n",
    "    def AndGateDelay : Int\n",
    "    def OrGateDelay : Int\n",
    "\n",
    "    class Wire{\n",
    "\n",
    "        private var sigVal = false\n",
    "        private var actions: List[Action] = List()  //connect wire to gates\n",
    "\n",
    "        def getSignal: Boolean = sigVal\n",
    "\n",
    "        def setSignal(s: Boolean) : Unit ={\n",
    "            if (s != sigVal ) {\n",
    "                sigVal = s\n",
    "\n",
    "                // when signal is changed,\n",
    "                // action is triggered\n",
    "                actions foreach (_())\n",
    "            }\n",
    "        }\n",
    "        def addAction(a: Action) : Unit ={\n",
    "            actions = a :: actions\n",
    "            // actions are triggered\n",
    "            a()\n",
    "        }\n",
    "\n",
    "    }\n",
    "    \n",
    "    def inverter(input: Wire, output: Wire): Unit = {\n",
    "        def invertAction(): Unit = {\n",
    "            val inputSig = input.getSignal\n",
    "            afterDelay(InverterDelay){\n",
    "                output setSignal !inputSig\n",
    "            }\n",
    "        }\n",
    "        input addAction invertAction\n",
    "    }\n",
    "    def andGate(input1: Wire, input2: Wire, output: Wire ): Unit ={\n",
    "        def andAction(): Unit = {\n",
    "            val in1Sig = input1.getSignal\n",
    "            val in2Sig = input2.getSignal\n",
    "            afterDelay(AndGateDelay){\n",
    "                output setSignal (in1Sig & in2Sig)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        input1 addAction andAction\n",
    "        input2 addAction andAction\n",
    "    }\n",
    "\n",
    "    def orGate(input1: Wire, input2: Wire, output: Wire ): Unit = {\n",
    "        def orAction(): Unit = {\n",
    "            val in1Sig = input1.getSignal\n",
    "            val in2Sig = input2.getSignal\n",
    "            afterDelay(OrGateDelay){\n",
    "                output setSignal (in1Sig | in2Sig)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        input1 addAction orAction\n",
    "        input2 addAction orAction\n",
    "    }\n",
    "\n",
    "\n",
    "    def probe(name: String, wire: Wire): Unit = {\n",
    "        def probeAcion(): Unit = {\n",
    "            println(s\"At time = $currentTime, $name wire = ${if (wire.getSignal) 1 else 0}\")\n",
    "        }\n",
    "        wire addAction probeAcion\n",
    "    }\n",
    "}\n",
    "\n",
    "abstract class Circuits extends Gates{\n",
    "\n",
    "    def halfAdder(a: Wire, b: Wire, s: Wire, c: Wire): Unit ={\n",
    "        //s: sum = a+b. 0 when a=b=0 or a=b=1, else 1\n",
    "        //c: carry = 1 when a=1, b=1, else 0\n",
    "        val d, e = new Wire\n",
    "        orGate(a,b,d)\n",
    "        andGate(a,b,c)\n",
    "        inverter(c,e)\n",
    "        andGate(d,e,s)\n",
    "    }\n",
    "\n",
    "    def fullAdder(a: Wire, b: Wire, cin: Wire, sum: Wire, cout: Wire): Unit ={\n",
    "        // sum = (a+b+cin) / 2\n",
    "        // cout = (a+b+cin) % 2\n",
    "        val s, c1, c2 = new Wire\n",
    "        halfAdder(b, cin, s, c1)\n",
    "        halfAdder(a, s, sum, c2)\n",
    "        orGate(c1,c2, cout)\n",
    "    }\n",
    "}\n",
    "\n",
    "object main extends App{\n",
    "    object sim extends Circuits with Parameters\n",
    "    import sim._\n",
    "\n",
    "    val in1, in2, sum, carry = new Wire\n",
    "\n",
    "    halfAdder(in1, in2, sum, carry)\n",
    "    probe(\"sum\", sum)\n",
    "    probe(\"carry\", carry)\n",
    "\n",
    "    in1 setSignal true\n",
    "\n",
    "    run()\n",
    "\n",
    "    in2 setSignal true\n",
    "    run()\n",
    "\n",
    "\n",
    "    in1 setSignal false\n",
    "    run()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "<a name ='ober'></a>\n",
    "### Observer Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/*\n",
    "    the follow codes are copied from Martin Odersky course\n",
    "     \n",
    "\n",
    "*/\n",
    "\n",
    "object main extends App {\n",
    "    \n",
    "    trait Subscriber {\n",
    "        def handler(pub: Publisher)\n",
    "    }\n",
    "\n",
    "    trait Publisher{\n",
    "        private var subscribers: Set[Subscriber] = Set()\n",
    "\n",
    "        def subscribe(sub: Subscriber): Unit = {\n",
    "            subscribers += sub\n",
    "        }\n",
    "\n",
    "        def unsubscribe(sub: Subscriber): Unit = {\n",
    "            subscribers -= sub\n",
    "        }\n",
    "\n",
    "        def publish():  Unit = {\n",
    "            subscribers.foreach(_.handler(this))\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    class BankAccount extends Publisher {\n",
    "        private var balance = 0  // Mutable States\n",
    "        def currentBalance = balance // getter, only read , no write\n",
    "        def deposit(amount: Int)  = {\n",
    "            if ( amount > 0 ) {\n",
    "                balance = balance + amount  \n",
    "                publish()\n",
    "            }\n",
    "\n",
    "        }\n",
    "        def withdraw (amount: Int) ={\n",
    "            if (0 < amount && amount <= balance) {\n",
    "                balance = balance - amount\n",
    "                publish()\n",
    "            }else throw new Error(\"insufficient funds\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    class Consolidator(observed: List[BankAccount]) extends Subscriber{\n",
    "\n",
    "        observed.foreach(_.subscribe(this))  //make Consolidator instance to subscribe\n",
    "                                             //the list of bankAccounts, which are publishers\n",
    "\n",
    "        private var total: Int = _ // uninitialize\n",
    "        compute() //calling compute() to initial total\n",
    "\n",
    "        def totalBalance = total\n",
    "\n",
    "        private def compute() =\n",
    "            total = observed.map(_.currentBalance).sum \n",
    "\n",
    "        def handler(pub: Publisher) = compute()\n",
    "\n",
    "\n",
    "    }\n",
    "\n",
    "\n",
    "    val a, b = new BankAccount\n",
    "    val c = new Consolidator(List(a, b))\n",
    "\n",
    "    println(c.totalBalance)\n",
    "    a deposit 20 \n",
    "    b deposit 30\n",
    "    println(c.totalBalance)\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/*\n",
    "\n",
    "Observer Pattern has a lot shortcomings, \n",
    "\n",
    "so instead of writing our own observer pattern, a new way is to use reactive programming library.\n",
    "\n",
    "See new book just released October, 2016\n",
    "\n",
    "    Reactive Programming with RxJava\n",
    "    Creating Asynchronous, Event-Based Applications\n",
    "    By Tomasz Nurkiewicz, Ben Christensen\n",
    "    \n",
    "\n",
    "    https://www.youtube.com/watch?v=-UVeBTeyDB0\n",
    "\n",
    "\n",
    "\n",
    "The scala.rx library  \n",
    "\n",
    "Created by Li Haoyi \n",
    "\n",
    "https://github.com/lihaoyi/scala.rx \n",
    "\n",
    "Also Netflix library http://reactivex.io/\n",
    "\n",
    " \n",
    "\n",
    "object main extends App {\n",
    "    import rx._\n",
    "\n",
    "    class BankAccount {\n",
    "        val balance  = Var(0)\n",
    "\n",
    "        def deposit(amount: Int)  = {\n",
    "            if ( amount > 0 ) {\n",
    "                balance() = balance.now + amount\n",
    "            }\n",
    "\n",
    "        }\n",
    "        def withdraw (amount: Int) ={\n",
    "            if (0 < amount && amount <= balance.now) {\n",
    "                balance() = balance.now - amount\n",
    "            }else throw new Error(\"insufficient funds\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "    val a1, b1 = new BankAccount\n",
    "    val c = Rx{a1.balance() + b1.balance()}\n",
    "\n",
    "    println(c.now)\n",
    "    a1 deposit 50\n",
    "    println(c.now)\n",
    "\n",
    "}\n",
    "\n",
    "*/\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'pppro'></a>\n",
    "## Parallel Programming in Scala\n",
    "\n",
    "Codes in this section are mostly copied from <br>Viktor Kuncak, Aleksandar Prokopec course on coursera https://www.coursera.org/learn/parprog1/<br>\n",
    "Aleksandar Prokopec course code:  https://github.com/axel22/parprog-snippets\n",
    "\n",
    "<a name = 'thread'></a>\n",
    "### Parallel Threads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world!\n",
      "I am from Main\n"
     ]
    }
   ],
   "source": [
    "class HelloWorld extends Thread{\n",
    "    override def run(): Unit = {\n",
    "        Thread.sleep(2000)\n",
    "        println(\"hello world!\")\n",
    "    }\n",
    "}\n",
    "\n",
    "val t = new HelloWorld\n",
    "t.start()\n",
    "t.join() //This tells the main thread to wait till t completes. \n",
    "         //Without it, main will go on to the next line\n",
    "println(\"I am from Main\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// When the two parallel threads are modifying the same variable Count, \n",
    "// output is not deterministic \n",
    "\n",
    "var uidCount = 0L\n",
    "\n",
    "def getUniqueID = {\n",
    "    Thread.sleep(100)\n",
    "    uidCount += 1\n",
    "    uidCount\n",
    "}\n",
    "\n",
    "def startThread()={\n",
    "    val t = new Thread{\n",
    "        override def run() = {\n",
    "            val uids = for ( x <- 0 until 10 ) yield getUniqueID\n",
    "            println(uids)\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "}\n",
    "\n",
    "startThread()\n",
    "startThread()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "//\n",
    "// one can wrap it in a object and use synchronized, \n",
    "//then JVM will allow one thread access the object at a time\n",
    "\n",
    "val x = new AnyRef {}\n",
    "var uidCount = 0\n",
    "\n",
    "def getUniqueID = x.synchronized {\n",
    "    Thread.sleep(100)\n",
    "    uidCount += 1\n",
    "    uidCount\n",
    "}\n",
    "\n",
    "def startThread()={\n",
    "    val t = new Thread{\n",
    "        override def run() = {\n",
    "            val uids = for ( x <- 0 until 10 ) yield getUniqueID\n",
    "            println(uids)\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "}\n",
    "\n",
    "startThread()\n",
    "startThread()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// this causes deadlock\n",
    "\n",
    "class Account(private var amount: Int = 0){\n",
    "    def transfer(target: Account, n: Int)  {\n",
    "        this.synchronized {        // the two locks \n",
    "            target.synchronized {  // each creats a lock, and they lock each other\n",
    "                this.amount -= n\n",
    "                target.amount += n\n",
    "            }\n",
    "        }\n",
    "\n",
    "    }\n",
    "}\n",
    "\n",
    "def StartThread(from: Account, to : Account, n: Int) = {\n",
    "    val t = new Thread {\n",
    "        override def run () = {\n",
    "            for (i <- 0 until n ) {\n",
    "                from.transfer(to, 1)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    t.start()\n",
    "    t\n",
    "}\n",
    "\n",
    "val a = new Account(500)\n",
    "val b = new Account(500)\n",
    "\n",
    "val t = StartThread(a, b, 100)\n",
    "val s = StartThread(b, a, 100)\n",
    "\n",
    "t.join()\n",
    "s.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// resolve deadlock by reverse the two locks\n",
    "\n",
    "\n",
    "val x = new AnyRef {}\n",
    "var uidCount = 0\n",
    "\n",
    "def getUniqueID = x.synchronized {\n",
    "    uidCount += 1\n",
    "    uidCount\n",
    "}\n",
    "\n",
    "\n",
    "class Account(var amount: Int = 0){\n",
    "\n",
    "    val uid = getUniqueID //each account gets an uniqueID\n",
    "\n",
    "    def balance: Int = amount\n",
    "\n",
    "    private def lockTransfer(target: Account, n: Int): Unit = {\n",
    "        this.synchronized {\n",
    "            target.synchronized {\n",
    "                this.amount -= n\n",
    "                target.amount += n\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def transfer(target: Account, n: Int) {\n",
    "        if (this.uid < target.uid)\n",
    "            this.lockTransfer(target, n)   \n",
    "        else\n",
    "            target.lockTransfer(this, -n)  //flip from and to with negative transfer\n",
    "    }\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "def StartThread(from: Account, to : Account, n: Int) = {\n",
    "        val t = new Thread {\n",
    "            override def run () = {\n",
    "                for (i <- 0 until n ) {\n",
    "                    from.transfer(to, 1)\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        t.start()\n",
    "        t\n",
    "    }\n",
    "\n",
    "val a = new Account(500)\n",
    "val b = new Account(500)\n",
    "\n",
    "val t = StartThread(a, b, 100)\n",
    "val s = StartThread(b, a, 200)\n",
    "\n",
    "t.join()\n",
    "s.join()\n",
    "\n",
    "a.uid\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//\n",
    "// copied from https://github.com/axel22/parprog-snippets/blob/master/src/main/scala/common/package.scala\n",
    "// this defines the parallel function will be used later\n",
    "// \n",
    "object para {\n",
    "    import java.util.concurrent._\n",
    "    import scala.util.DynamicVariable\n",
    "\n",
    "    val forkJoinPool = new ForkJoinPool\n",
    "\n",
    "    val scheduler =\n",
    "        new DynamicVariable[TaskScheduler](new DefaultTaskScheduler)\n",
    "\n",
    "\n",
    "    def task[T](body: => T): ForkJoinTask[T] = {\n",
    "        scheduler.value.schedule(body)\n",
    "    }\n",
    "\n",
    "    abstract class TaskScheduler {\n",
    "        def schedule[T](body: => T): ForkJoinTask[T]\n",
    "    }\n",
    "\n",
    "    class DefaultTaskScheduler extends TaskScheduler {\n",
    "        def schedule[T](body: => T): ForkJoinTask[T] = {\n",
    "            val t = new RecursiveTask[T] {\n",
    "                def compute = body\n",
    "            }\n",
    "            forkJoinPool.execute(t)\n",
    "            t\n",
    "        }\n",
    "    }\n",
    "\n",
    "    def parallel[A, B](taskA: => A, taskB: => B): (A, B) = {\n",
    "        val right = task {\n",
    "            taskB\n",
    "        }\n",
    "        val left = taskA\n",
    "        (left, right.join())\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1412"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// Monte Carlo Pi in 4 parallel threads\n",
    "//\n",
    "\n",
    "\n",
    "import scala.util.Random\n",
    "\n",
    "def mcCount(iter: Int) : Int = {\n",
    "    val randomX = new Random()\n",
    "    val randomY = new Random()\n",
    "    var hits = 0\n",
    "    for ( i <- 0 until iter ) {\n",
    "        val x = randomX.nextDouble()\n",
    "        val y = randomY.nextDouble()\n",
    "        if (x*x + y*y < 1) hits += 1\n",
    "    }\n",
    "    hits\n",
    "}\n",
    "\n",
    "def monterCarloPiPar(iter: Int): Double = {\n",
    "    val smalliter = iter/4\n",
    "    val ((pi1,pi2),(pi3,pi4)) = para.parallel(\n",
    "        para.parallel(mcCount(smalliter), mcCount(smalliter)),\n",
    "        para.parallel(mcCount(smalliter), mcCount(iter-3*smalliter)))\n",
    "\n",
    "    4.0*(pi1+pi2+pi3+pi4)/iter\n",
    "}\n",
    "\n",
    "monterCarloPiPar(40000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'par'></a>\n",
    "### Parallel Algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array (first 10 items): List(9909, 917, 4866, 8537, 2226, 9163, 9208, 4529, 5129, 3310)\n",
      "Sorted (first 10 itmes): List(0, 0, 0, 3, 4, 4, 7, 7, 8, 8)\n",
      "\n",
      "time for parallel merge sort: 0.108155505 seconds\n",
      "time for sequential quicksort: 0.095088366 seconds\n"
     ]
    }
   ],
   "source": [
    "/*\n",
    "    Because of JIT compilation, run this cell at least once to get an answer\n",
    "*/\n",
    "\n",
    "//\n",
    "// parallel merge sort\n",
    "//\n",
    "\n",
    "val rand = new Random()\n",
    "val leng = 10000\n",
    "\n",
    "//unlike List, elements of Array are mutable\n",
    "val xs =  (for (i <- 0 until leng ) yield rand.nextInt(10000)).toArray\n",
    "val ys = new Array[Int](leng)\n",
    " \n",
    "def merge(src: Array[Int], dst: Array[Int], from: Int, mid: Int, to: Int) {\n",
    "    var left = from\n",
    "    var right = mid\n",
    "    var i = from\n",
    "    while (left < mid && right < to) {\n",
    "        while (left < mid && src(left) <= src(right)) {\n",
    "            dst(i) = src(left)\n",
    "            i += 1\n",
    "            left += 1\n",
    "        }\n",
    "        while (right < to && src(right) <= src(left)) {\n",
    "            dst(i) = src(right)\n",
    "            i += 1\n",
    "            right += 1\n",
    "        }\n",
    "    }\n",
    "    while (left < mid) {\n",
    "        dst(i) = src(left)\n",
    "        i += 1\n",
    "        left += 1\n",
    "    }\n",
    "    while (right < to) {\n",
    "        dst(i) = src(right)\n",
    "        i += 1\n",
    "        right += 1\n",
    "    }\n",
    "}\n",
    "\n",
    "val maxDepth = 4 //parallel depth\n",
    "\n",
    "def mergeSort(xs: Array[Int], from: Int, to: Int, depth: Int = 0): Unit= {\n",
    "    if (depth == maxDepth) {\n",
    "        java.util.Arrays.sort(xs, from, to) //this is java in-place quickSort \n",
    "        if (maxDepth == 0)\n",
    "            println(\"Sorted\" + xs.toList.take(10))\n",
    "    }\n",
    "    else{\n",
    "        val mid = (from + to)/2\n",
    "        mergeSort(xs,  from, mid, depth + 1)\n",
    "        mergeSort(xs,  mid, to, depth + 1)\n",
    "        val flip = (maxDepth - depth) % 2 == 0\n",
    "        val src = if (flip) ys else xs\n",
    "        val dst = if (flip) xs else ys\n",
    "        merge(src, dst, from, mid, to)\n",
    "        if (depth == 0)\n",
    "            println(\"Sorted (first 10 itmes): \" + dst.toList.take(10))\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "println(\"Array (first 10 items): \" + xs.toList.take(10))\n",
    "\n",
    "val t0 = System.nanoTime()\n",
    "mergeSort(xs,  0 , leng) \n",
    "println(\"\\ntime for parallel merge sort: \"+(System.nanoTime()-t0)/1e9+\" seconds\")\n",
    "\n",
    "\n",
    "val t1 = System.nanoTime()\n",
    "java.util.Arrays.sort(xs,  0 , leng) \n",
    "println(\"time for sequential quicksort: \"+(System.nanoTime()-t1)/1e9+\" seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(2, 4, 6, 8)\n",
      "10\n",
      "110\n",
      "List(100, 101, 103, 106, 110)\n"
     ]
    }
   ],
   "source": [
    "// Parallelize\n",
    "//    map, reduce/fold, scan on collections \n",
    "// \n",
    "println(List(1,2,3,4).map(2*_))\n",
    "println(List(1,2,3,4).reduce(_+_))\n",
    "println(List(1,2,3,4).fold(100)(_+_))\n",
    "println(List(1,2,3,4).scan(100)(_+_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for sequential map: 0.134020695 seconds\n",
      "time for parallel map: 0.17011698 seconds\n",
      "results: List(0, 1, 4, 9, 16, 25, 36, 49, 64, 81)\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// parallel operations on collections: map on array\n",
    "//\n",
    "\n",
    "\n",
    "val leng = 1000000\n",
    "\n",
    "val threshold = leng/10\n",
    "\n",
    "val xs =  (for (i <- 0 until leng ) yield i).toArray\n",
    "val ys = new Array[Int](leng)\n",
    "\n",
    "def f(x:Int) = x*x\n",
    "\n",
    "\n",
    "def mapSeqSeq[A, B](in: Array[A], out: Array[B], f: A => B, left: Int, right: Int): Unit = {\n",
    "    var i = left\n",
    "    while  ( i < right){\n",
    "        out(i) = f(in(i))\n",
    "        i += 1\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "def mapSeqPar[A, B](in: Array[A], out: Array[B], f: A => B, left: Int, right: Int): Unit = {\n",
    "    if (right-left < threshold  ) mapSeqSeq(in, out, f, left, right)\n",
    "    else {\n",
    "        val mid = left + (right - left) / 2\n",
    "        para.parallel(mapSeqPar(in, out, f, left, mid), mapSeqPar(in, out, f, mid, right))\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "val t0 = System.nanoTime()\n",
    "mapSeqSeq(xs, ys, f, 0 , leng)\n",
    "println(\"time for sequential map: \"+(System.nanoTime()-t0)/1e9+\" seconds\")\n",
    "\n",
    "val t1 = System.nanoTime()\n",
    "mapSeqPar(xs, ys, f, 0 , leng)\n",
    "println(\"time for parallel map: \"+(System.nanoTime()-t1)/1e9+\" seconds\")\n",
    "\n",
    "println(\"results: \"+ys.toList.take(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ { { List(1, 2, 0, 0) , List(3, 4, 5, 0) } , { List(6, 7, 0, 0) , List(8, 9, 10, 0) } } , { { List(11, 12, 0, 0) , List(13, 14, 15, 0) } , { List(16, 17, 0, 0) , List(18, 19, 20, 0) } } }"
     ]
    }
   ],
   "source": [
    "//\n",
    "// parallel operations on collections:  map on tree\n",
    "//\n",
    "\n",
    "sealed abstract class aTree[A] {val size: Int}\n",
    "case class aLeaf[A](a: Array[A]) extends aTree[A]{  // leaf has no children nodes\n",
    "override val size: Int = a.size               //  a is the data\n",
    "override def toString: String = a.toList.toString\n",
    "}\n",
    "case class aNode[A](left: aTree[A], right: aTree[A]) extends aTree[A]{  //node has l/r children\n",
    "override val size: Int = left.size + right.size                 //but has no data\n",
    "override def toString: String = \"{ \"+left.toString +\" , \"+ right.toString + \" }\"\n",
    "}\n",
    "\n",
    "\n",
    "//trees are immutable, hence return a copy of a apply mapped tree\n",
    "def mapTreePar(t: aTree[Int], f: Int => Int): aTree[Int] = t match {\n",
    "    case aNode(l, r) => {\n",
    "        val (lb, rb) = para.parallel(mapTreePar(l,f), mapTreePar(r,f))\n",
    "        aNode(lb, rb)\n",
    "    }\n",
    "    case aLeaf(a) => {\n",
    "        val len = a.length\n",
    "        val b = new Array[Int](len)\n",
    "        for (i <- 0 until len) b(i) = f(a(i))\n",
    "        aLeaf(b)\n",
    "    }\n",
    "}\n",
    "\n",
    "var count = 1\n",
    "val leafSize = 4\n",
    "\n",
    "def makeTree(n: Int): aTree[Int] = {\n",
    "    if (n <= leafSize){\n",
    "        val a = new Array[Int](leafSize)\n",
    "        for (i <- 0 until n) {\n",
    "            a(i) = count\n",
    "            count += 1\n",
    "        }\n",
    "        aLeaf(a)\n",
    "    }\n",
    "    else\n",
    "        aNode(makeTree(n/2) , makeTree(n-n/2))\n",
    "}\n",
    "\n",
    "\n",
    "val num = 20\n",
    "print( mapTreePar(makeTree(num), (x:Int) => x) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "( ( ( 22 - 23 ) - ( 24 - ( 25 - 26 ) ) ) - ( ( 27 - 28 ) - ( 29 - ( 30 - 31 ) ) ) )\n",
      "apply reducer at tree level, result = 5\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// parallel operations on collections:  reduce / fold on tree\n",
    "//\n",
    "\n",
    "\n",
    "sealed abstract class Tree[A]\n",
    "\n",
    "case class Leaf[A](value: A) extends Tree[A] {\n",
    "    // leaf has no children nodes, only store value\n",
    "    override def toString: String = value.toString\n",
    "}\n",
    "case class Node[A](left: Tree[A], right: Tree[A]) extends Tree[A]{  //node has l/r children\n",
    "\n",
    "    override def toString: String = \"( \"+left.toString +\" - \"+ right.toString + \" )\"\n",
    "}\n",
    "\n",
    "// reducce a tree to s single element A\n",
    "def reduceTreePar[A](t: Tree[A], f: (A, A) => A): A = t match {\n",
    "    case Node(l, r) => {\n",
    "        val (lb, rb) = para.parallel(reduceTreePar(l,f), reduceTreePar(r,f))\n",
    "        f(lb, rb)\n",
    "    }\n",
    "    case Leaf(a) => a\n",
    "}\n",
    "\n",
    "val num = 10\n",
    "var count = 0\n",
    "\n",
    "def makeTree(n: Int): Tree[Int] = {\n",
    "    if (n <= 1){\n",
    "        count += 1\n",
    "        Leaf(count)\n",
    "    }\n",
    "    else\n",
    "        Node(makeTree(n/2) , makeTree(n-n/2))\n",
    "}\n",
    "\n",
    "val tt = makeTree(num)\n",
    "val tt_reduce = reduceTreePar(tt, (x:Int,y:Int)=> x - y)\n",
    "println(tt)\n",
    "println(s\"apply reducer at tree level, result = $tt_reduce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:69: error: type mismatch;\n",
       " found   : Account\n",
       " required: Int\n",
       "       scanLeft(in, a,  (x:Int, y:Int) => x+y)\n",
       "                    ^\n",
       "StackTrace: "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// parallel operations on collections:  scan on array  \n",
    "//   the operation has to be associative, so the array will be converted to a (balance) reduction tree\n",
    "//  if the operation is not associative, then right/left scan is essentially a one-sided tree\n",
    "//  so parallelism has no advantages\n",
    "//\n",
    "//  O(log n)\n",
    "//\n",
    "\n",
    "sealed abstract class TreeRes[A]{var res: A}\n",
    "\n",
    "case class LeafRes[A](override var res: A) extends TreeRes[A] {\n",
    "    // leaf has no children nodes, only store value\n",
    "    override def toString: String = res.toString\n",
    "}\n",
    "case class NodeRes[A](left: TreeRes[A], override var res: A , right: TreeRes[A]) extends TreeRes[A]{  //node has l/r children\n",
    "\n",
    "    //override def toString: String =  \"{\"+ left.toString +\", \"+res+\", \"+ right.toString +\"}\"\n",
    "    override def toString: String =  left.toString +\", \"+ right.toString\n",
    "} \n",
    "\n",
    "val in = (for (i <- 1 to 10) yield i).toArray\n",
    "val a = 100 //fold accumulator\n",
    "val out = new Array[Int](in.length+1)\n",
    "out(0) = a\n",
    "\n",
    "//use the intermediate tree created by makeTree, apply the accumulator a and get the correct sequence\n",
    "def downsweep(t: TreeRes[Int], a: Int, f:(Int, Int)=>Int ,left: Int, right: Int): Unit = t match {\n",
    "    case  LeafRes(v) => {\n",
    "         out(left+1) = Integer.parseInt(f(a, t.res).toString);\n",
    "    }\n",
    "    case NodeRes(l, v, r) => {\n",
    "        val mid = left + ( right - left ) / 2\n",
    "         para.parallel(downsweep(l, a, f, left, mid), downsweep(r,f(a, l.res),f, mid, right))\n",
    "    }\n",
    "}\n",
    "\n",
    "//create a temp tree, and apply f to the tree structure and store the intermediate result to the node\n",
    "def makeTree(in: Array[Int],  f:(Int,Int) => Int, left: Int, right: Int): TreeRes[Int] = {\n",
    "    if (left == right - 1){\n",
    "        LeafRes(in(left))\n",
    "    }\n",
    "    else{\n",
    "        val mid = left + ( right - left ) / 2\n",
    "        val (tl, tr) =  para.parallel(makeTree(in, f, left, mid) , makeTree(in, f, mid, right))\n",
    "        NodeRes(tl,f(tl.res, tr.res) , tr)\n",
    "    }\n",
    "}\n",
    "\n",
    "def scanLeft(in: Array[Int], a: Int, f:(Int,Int) => Int) = {\n",
    "    val t1 = makeTree(in,   f, 0 , in.length) \n",
    "    downsweep(t1, a, f, 0 , in.length)\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "println (in.toList)\n",
    "\n",
    "scanLeft(in, a,  (x:Int, y:Int) => x+y)\n",
    "\n",
    "println (out.toList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='dataStr'></a>\n",
    "### Parallel Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Scala Collections and Parallel Collections Hierarchy\n",
    "![](http://docs.scala-lang.org/resources/images/parallel-collections-hierarchy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParVector(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//\n",
    "// Par \n",
    "//\n",
    "\n",
    "for (i <- (1 to 20).par)  yield i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ListBuffer(11, 8, 18, 3, 9, 12, 17, 19, 4, 10, 20, 5, 13, 14, 15, 7, 6, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "import scala.collection.mutable.ListBuffer\n",
    "var ll = new ListBuffer[Int]()\n",
    "for (i <- (1 to 20).par) {\n",
    "    ll += i  \n",
    "}\n",
    "println(ll)  // showing the data are processing in parallel and the order is not deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate pi : 3.1363150640927047\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// Just make sure, writing and reading are not atomic\n",
    "// \n",
    "// Calculate Pi using Par\n",
    "\n",
    "import scala.util.Random\n",
    " \n",
    "val randomX = new Random()\n",
    "val randomY = new Random()\n",
    "var hits = 0\n",
    "var nonhits = 0\n",
    "\n",
    "for ( i <- (0 until 2000000).par ) {\n",
    "    val x = randomX.nextDouble()\n",
    "    val y = randomY.nextDouble()\n",
    "    if (x*x + y*y < 1) hits += 1   // only writing to hits/nonhits\n",
    "    else nonhits += 1              // no reading from hits/nonhits  \n",
    "}\n",
    "\n",
    "println(\"estimate pi : \" + (4.0*hits)/(hits+nonhits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time for parallel: 0.460319134 seconds\n",
      "time for sequential: 1.46092184 seconds\n"
     ]
    }
   ],
   "source": [
    "//\n",
    "// let us check the time \n",
    "//\n",
    "\n",
    "val t0 = System.nanoTime()\n",
    "(1 to 100000000).par.count(i => i%3==0)\n",
    "println(\"time for parallel: \"+(System.nanoTime()-t0)/1e9+\" seconds\")\n",
    "\n",
    "val t1 = System.nanoTime()\n",
    "(1 to 100000000).count(i => i%3==0)\n",
    "println(\"time for sequential: \"+(System.nanoTime()-t1)/1e9+\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// the count method above may run in parallel or sequential in the split data set \n",
    "// and it bases on sum method\n",
    "\n",
    "// So how parallel sum works in parallel?\n",
    "\n",
    "// it first distributes data parallel, then use the parallel fold method we discussed before \n",
    "// or sequential fold if the redistribute sets are not too big.\n",
    "\n",
    "\n",
    "def sum(xs: Array[Int]): Int = xs.par.fold(0)(_+_)\n",
    "\n",
    "// similar idea apply to max, because they are associative op\n",
    "\n",
    "def max(xs: Array[Int]): Int = xs.par.fold(Int.MaxValue)(math.max)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// fold is more restrict because it requires the two operands to be same type\n",
    "\n",
    "// Use aggregate to replace fold\n",
    "\n",
    "// a sequence of type A, accumulator in type B\n",
    "\n",
    "// def aggregate[B](z:  B)(seqop: (B, A)  B, combop: (B, B)  B): B\n",
    "\n",
    "Array(\"Hello\",\"How\",\"are\",\"you\").par.\n",
    "    aggregate(0)((count, c)=> if (c.length == 3) count + 1 else count, _+_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " Finally we discuss how par works? first split (splitter) the collection then combine (combiner) them. \n",
    " Both should be in O(log N).\n",
    " \n",
    " Ref: http://docs.scala-lang.org/overviews/parallel-collections/custom-parallel-collections.html\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "empty iterator"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val A = Iterator(1,2,3,4, 5)   //Iterator is a base of all collections\n",
    "while (A.hasNext) println(A.next()) \n",
    "A // hence A is a pointer attached to the first element in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "// sequence splitter starts on line 542 \n",
    "// https://github.com/scala/scala/blob/v2.12.0-RC1/src/library/scala/collection/parallel/RemainsIterator.scala#L542\n",
    "\n",
    "trait Iterator[A]{\n",
    "    def next() : A\n",
    "    def hasNext: Boolean\n",
    "}\n",
    "\n",
    "trait Splitter[A] extends Iterator[A]{\n",
    "    def split: Seq[Splitter[A]]\n",
    "    def remaining: Int\n",
    "}\n",
    "\n",
    "trait Builder[A, B] {  //A type of element of collection, B type of the collection, \n",
    "    def +=(elem: A) : Builder[A, B]\n",
    "    def result: B\n",
    "}\n",
    "\n",
    "trait Combiner[A, B] extends Builder[A,B]{\n",
    "    def combine(that: Combiner[A,B]): Combiner[A,B]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='akka'></a>\n",
    "### Concurrency & Actors Model\n",
    "\n",
    "message-oriented programming model and actor model. No share memory and instead passing variables like in MPI.  Java library\n",
    "\n",
    "http://akka.io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "/*\n",
    "    Run this cell in an ide, it will print \"action received\" \n",
    "    \n",
    "*/\n",
    "\n",
    "\n",
    "object main extends App {\n",
    "    import akka.actor._\n",
    "\n",
    "    class Action extends Actor {\n",
    "        def receive = {\n",
    "            case \"action\" => println(\"action received\")\n",
    "            case _ => println(\"something else\")\n",
    "        }\n",
    "    }\n",
    "\n",
    "    val A = ActorSystem(\"Action\")\n",
    "    val act = A.actorOf(Props[Action], \"Action\")\n",
    "\n",
    "    act ! \"action\"   //the String \"action\" is passed to the actor on a separated thread\n",
    "\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name='Spark'></a>\n",
    "# Big Data, Distributed Analysis with Spark\n",
    "\n",
    "Spark is better than Hadoop MapReduce, because in addition it is 10 times faster and it runs on Hadoop clusters, Spark provides in-memory caching and real-time data processing. \n",
    "\n",
    "It has four components:\n",
    " - Spark SQL (similar to hive in hadoop)\n",
    " - Spark Streaming (similar to Flink)\n",
    " - GraphX\n",
    " - ML lib\n",
    " \n",
    "\n",
    "![](https://databricks.com/wp-content/uploads/2016/06/spark-logo-trademark.png)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name = 'scalaspark'></a>  \n",
    "## Spark Streaming - Twitter Sentiment Analysis in Real Time\n",
    "\n",
    "This following app will process twitter feeds in real time  and produces the happiest hashtag from the last 60 seconds.\n",
    "\n",
    "\n",
    "\n",
    "copied from https://github.com/apache/bahir/blob/master/streaming-twitter/examples/src/main/scala/org/apache/spark/examples/streaming/twitter/TwitterHashTagJoinSentiments.scala\n",
    "   \n",
    "\n",
    "Berkeley AMP Lab http://ampcamp.berkeley.edu/3/exercises/realtime-processing-with-spark-streaming.html\n",
    "\n",
    "Databricks https://github.com/databricks/spark-training/blob/master/streaming/scala/TutorialHelper.scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "/*\n",
    "\n",
    "object main extends App {\n",
    " \n",
    "\n",
    "    import org.apache.spark.SparkContext\n",
    "    import org.apache.spark.SparkConf\n",
    "\n",
    "    import org.apache.log4j.{Level, Logger}\n",
    "    import org.apache.spark.streaming._\n",
    "    import org.apache.spark.streaming.{Seconds, StreamingContext}\n",
    "    import org.apache.spark.streaming.twitter.TwitterUtils\n",
    "\n",
    " \n",
    "    //   OAuth credentials\n",
    "    val consumerKey = \"hth8cYGEudYJAmKWfjmEKieAbu\"\n",
    "    val consumerSecret = \"dd5dGzoODyhR4cZTdPHKJTIPJEs9CeP2qPjxDjiDSKdogUEj\"\n",
    "    val accessToken = \"2813163296-mIzkxDQKt0k1LWTUhfsWDRvf4lshovH84u3J3m\"\n",
    "    val accessTokenSecret = \"45RN05C7vc5aqhHl3paogTx2DGk1zB8L7Ta3nU4vDsfDAz\"\n",
    "       \n",
    "    System.setProperty(\"twitter4j.oauth.consumerKey\", consumerKey)\n",
    "    System.setProperty(\"twitter4j.oauth.consumerSecret\", consumerSecret)\n",
    "    System.setProperty(\"twitter4j.oauth.accessToken\", accessToken)\n",
    "    System.setProperty(\"twitter4j.oauth.accessTokenSecret\", accessTokenSecret)\n",
    "\n",
    "    val sparkConf = new SparkConf().setAppName(\"HStreet\").setMaster(\"local[2]\") \n",
    "    val ssc = new StreamingContext(sparkConf, Seconds(2))\n",
    "    val stream = TwitterUtils.createStream(ssc, None)\n",
    "\n",
    "    val hashTags = stream.flatMap(status => status.getText.split(\" \").filter(_.startsWith(\"#\")))\n",
    "\n",
    "    // Read in the word-sentiment list and create a static RDD from it\n",
    "    //save https://raw.githubusercontent.com/apache/bahir/master/streaming-twitter/examples/data/AFINN-111.txt\n",
    "    val wordSentimentFilePath = \"AFINN-111.txt\"\n",
    "    val wordSentiments = ssc.sparkContext.textFile(wordSentimentFilePath).map { line =>\n",
    "        val Array(word, happinessValue) = line.split(\"\\t\")\n",
    "        (word, happinessValue.toInt)\n",
    "    }.cache() \n",
    "\n",
    "    // Determine the hash tags with the highest sentiment values by joining the streaming RDD\n",
    "    // with the static RDD inside the transform() method and then multiplying\n",
    "    // the frequency of the hash tag by its sentiment value\n",
    "    val happiest60 = hashTags.map(hashTag => (hashTag.tail, 1))\n",
    "            .reduceByKeyAndWindow(_ + _, Seconds(60))\n",
    "            .transform{topicCount => wordSentiments.join(topicCount)}\n",
    "            .map{case (topic, tuple) => (topic, tuple._1 * tuple._2)}\n",
    "            .map{case (topic, happinessValue) => (happinessValue, topic)}\n",
    "            .transform(_.sortByKey(false))\n",
    "\n",
    "    // Print hash tags with the most positive sentiment values\n",
    "    happiest60.foreachRDD(rdd => {\n",
    "        val topList = rdd.take(10)\n",
    "        println(\"\\nHappiest topics in last 60 seconds (%s total):\".format(rdd.count()))\n",
    "        topList.foreach{case (happiness, tag) => println(\"%s (%s happiness)\".format(tag, happiness))}\n",
    "    })\n",
    " \n",
    "    ssc.start()\n",
    "    ssc.awaitTermination()\n",
    "\n",
    "}\n",
    "*/\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name = \"ssql\"></a> \n",
    "## Spark GraphX - Page Ranking Application\n",
    "\n",
    "http://ampcamp.berkeley.edu/big-data-mini-course/graph-analytics-with-graphx.html\n",
    "\n",
    "Data: https://github.com/databricks/spark-training/tree/master/data/graphx\n",
    "There are two columns in graphx-wiki-vertices.txt, one is the id, the other is an English key phrase. Each line in graphx-wiki-edges.txt is a connection by 2 ids. This makes an undirected graph.\n",
    "\n",
    "E.g. from the graph if \"A\" is connected to \"B\", \"C\" and \"D\" (first degree connection), then a web page that contains words \"B\",  \"C\" and \"D\" should have higher rank to the key search word \"A\".\n",
    "\n",
    "For details http://www.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture3/lecture3.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import org.apache.spark.graphx._\n",
    "import org.apache.spark.rdd.RDD\n",
    "\n",
    "val vertexArray = Array(\n",
    "  (1L, (\"Alice\", 28)),\n",
    "  (2L, (\"Bob\", 27)),\n",
    "  (3L, (\"Charlie\", 65)),\n",
    "  (4L, (\"David\", 42)),\n",
    "  (5L, (\"Ed\", 55)),\n",
    "  (6L, (\"Fran\", 50))\n",
    "  )\n",
    "val edgeArray = Array(\n",
    "  Edge(2L, 1L, 7),  //the weigth indicating how much one likes the other\n",
    "  Edge(2L, 4L, 2),\n",
    "  Edge(3L, 2L, 4),\n",
    "  Edge(3L, 6L, 3),\n",
    "  Edge(4L, 1L, 1),\n",
    "  Edge(5L, 2L, 2),\n",
    "  Edge(5L, 3L, 8),\n",
    "  Edge(5L, 6L, 3)\n",
    "  )\n",
    "\n",
    "val vertexRDD: RDD[(Long, (String, Int))] = sc.parallelize(vertexArray)\n",
    "val edgeRDD: RDD[Edge[Int]] = sc.parallelize(edgeArray)\n",
    "val graph: Graph[(String, Int), Int] = Graph(vertexRDD, edgeRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r",
      "Bob likes Alice\n",
      "Bob likes David\n",
      "Charlie likes Bob\n",
      "Charlie likes Fran\n",
      "David likes Alice\n",
      "Ed likes Bob\n",
      "Ed likes Charlie\n",
      "Ed likes Fran\n"
     ]
    }
   ],
   "source": [
    "// display the edage show who likes who\n",
    "\n",
    "for (triplet <- graph.triplets.collect) {\n",
    "  println(s\"${triplet.srcAttr._1} likes ${triplet.dstAttr._1}\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name = \"sml\"></a> \n",
    "## Spark MLlib \n",
    "\n",
    "### ALS - Movie Recommendation System \n",
    "\n",
    "The following program will output movie recommendations to users, using alternative least square matrix factorization.\n",
    "\n",
    "From users who have similar movie rating preference, to predict what a user may want to watch.\n",
    "\n",
    "\n",
    "Three data files: \n",
    "\n",
    "users.dat contains 6000 active users (each users have rated > 20 movies)   \n",
    "\n",
    "    UserID::Gender::Age::Occupation::Zip-code\n",
    "\n",
    "movies.dat contais 4000 movies \n",
    "\n",
    "    MovieID::Title::Genres\n",
    "    \n",
    "ratings.dat contains 1 million ratings, the scale is 1-5 \n",
    "\n",
    "    UserID::MovieID::Rating::Timestamp\n",
    "\n",
    "<br>\n",
    "\n",
    "Data: https://github.com/databricks/spark-training/tree/master/data/movielens/medium\n",
    "\n",
    "\n",
    "Explanation: http://ampcamp.berkeley.edu/big-data-mini-course/movie-recommendation-with-mllib.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1000209 number of ratings from 6040 users on 3706 movies.\n"
     ]
    }
   ],
   "source": [
    "//modified from https://github.com/databricks/spark-training/blob/master/machine-learning/scala/solution/MovieLensALS.scala\n",
    "\n",
    "import java.io.File\n",
    "import scala.io.Source\n",
    "import org.apache.log4j.Logger\n",
    "import org.apache.log4j.Level\n",
    "import org.apache.spark.SparkConf\n",
    "import org.apache.spark.SparkContext\n",
    "import org.apache.spark.SparkContext._\n",
    "import org.apache.spark.rdd._\n",
    "import org.apache.spark.mllib.recommendation.{ALS, Rating, MatrixFactorizationModel}\n",
    "\n",
    "//load ratings\n",
    "val ratings = sc.textFile(\"ratings.dat\").map { line =>\n",
    "        val fields = line.split(\"::\") \n",
    "      (fields(3).toLong % 10, Rating(fields(0).toInt, fields(1).toInt, fields(2).toDouble))\n",
    "    }\n",
    "\n",
    "val numRatings = ratings.count()\n",
    "val numUsers = ratings.map(_._2.user).distinct().count()\n",
    "val numMovies = ratings.map(_._2.product).distinct().count()\n",
    "\n",
    "println(\"We have \" + numRatings + \" number of ratings from \"\n",
    "    + numUsers + \" users on \" + numMovies + \" movies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "//load movies\n",
    "\n",
    "val movies = sc.textFile(\"movies.dat\").map { line =>\n",
    "        val fields = line.split(\"::\") \n",
    "        (fields(0).toInt, fields(1)) }.collect().toMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: 602241, validation: 198919, test: 199049\n"
     ]
    }
   ],
   "source": [
    "//split data into training, test and cache RDD\n",
    "\n",
    "val numPartitions = 4\n",
    "val training = ratings.filter(x => x._1 < 6).values.repartition(numPartitions).cache()\n",
    "val validation = ratings.filter(x => x._1 >= 6 && x._1 < 8).values.repartition(numPartitions).cache()\n",
    "val test = ratings.filter(x => x._1 >= 8).values.cache()\n",
    "\n",
    "val numTraining = training.count()\n",
    "val numValidation = validation.count()\n",
    "val numTest = test.count()\n",
    "    \n",
    "println(\"Training: \" + numTraining + \", validation: \" + numValidation + \", test: \" + numTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 0.880 for the model trained with rank = 8, lambda = 0.1, and numIter = 10.\n",
      "RMSE = 0.872 for the model trained with rank = 8, lambda = 0.1, and numIter = 20.\n",
      "RMSE = 3.756 for the model trained with rank = 8, lambda = 10.0, and numIter = 10.\n",
      "RMSE = 3.756 for the model trained with rank = 8, lambda = 10.0, and numIter = 20.\n",
      "RMSE = 0.877 for the model trained with rank = 12, lambda = 0.1, and numIter = 10.\n",
      "RMSE = 0.871 for the model trained with rank = 12, lambda = 0.1, and numIter = 20.\n",
      "RMSE = 3.756 for the model trained with rank = 12, lambda = 10.0, and numIter = 10.\n",
      "RMSE = 3.756 for the model trained with rank = 12, lambda = 10.0, and numIter = 20.\n",
      "\n",
      "time for training: 32.996611969 seconds\n"
     ]
    }
   ],
   "source": [
    "// ALS algorithm\n",
    "// spark.apache.org/docs/0.8.1/api/mllib/org/apache/spark/mllib/recommendation/package.html\n",
    "\n",
    "\n",
    "//hyperparameters\n",
    "val ranks = List(8, 12)\n",
    "val lambdas = List(0.1, 10.0)\n",
    "val numIters = List(10, 20)\n",
    "\n",
    "var bestModel: Option[MatrixFactorizationModel] = None\n",
    "var bestValidationRmse = Double.MaxValue\n",
    "var bestRank = 0\n",
    "var bestLambda = -1.0\n",
    "var bestNumIter = -1\n",
    "\n",
    "def computeRmse(model: MatrixFactorizationModel, data: RDD[Rating], n: Long): Double = {\n",
    "    val predictions: RDD[Rating] = model.predict(data.map(x => (x.user, x.product)))\n",
    "    val predictionsAndRatings = predictions.map(x => ((x.user, x.product), x.rating)).join(\n",
    "        data.map(x => ((x.user, x.product), x.rating))).values\n",
    "    math.sqrt(predictionsAndRatings.map(x => (x._1 - x._2) * (x._1 - x._2)).reduce(_ + _) / n)\n",
    "}\n",
    "\n",
    "\n",
    "val t1 = System.nanoTime()\n",
    "for (rank <- ranks; lambda <- lambdas; numIter <- numIters) \n",
    "{\n",
    "    val model = ALS.train(training, rank, numIter, lambda)  //training\n",
    "    val validationRmse = computeRmse(model, validation, numValidation) //error on validation set\n",
    "    \n",
    "    println(\"RMSE = \" + f\"$validationRmse%1.3f\" + \" for the model trained with rank = \" \n",
    "        + rank + \", lambda = \" + lambda + \", and numIter = \" + numIter + \".\")\n",
    "    if (validationRmse < bestValidationRmse) \n",
    "    {\n",
    "            bestModel = Some(model)\n",
    "            bestValidationRmse = validationRmse\n",
    "            bestRank = rank\n",
    "            bestLambda = lambda\n",
    "            bestNumIter = numIter\n",
    "    }\n",
    "}\n",
    "println(\"\\ntime for training: \"+(System.nanoTime()-t1)/1e9+\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model was trained with rank = 12 and lambda = 0.1, and numIter = 20\n",
      "The RMSE on the test set is 0.869.\n"
     ]
    }
   ],
   "source": [
    "// evaluate the best model on the test set\n",
    "\n",
    "val testRmse = computeRmse(bestModel.get, test, numTest)\n",
    "    println(\"The best model was trained with rank = \" + bestRank + \" and lambda = \" + bestLambda\n",
    "+ \", and numIter = \" + bestNumIter + \"\\nThe RMSE on the test set is \" +  f\"$testRmse%1.3f\"+ \".\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name='otherML'></a>\n",
    "### Other Big Data Machine Learning Algorithms & Big Data Statistics Tools\n",
    "\n",
    "Import Statistics\n",
    "\n",
    "    org.apache.spark.mllib.stat.Statistics.colStats\n",
    "\n",
    "Import Optimization\n",
    "\n",
    "    org.apache.spark.mllib.optimization.{LBFGS, LogisticGradient, SquaredL2Updater}\n",
    "    \n",
    "Classification\n",
    "\n",
    "    org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "    org.apache.spark.mllib.classification{LogisticRegressionModel, SVMModels, NaiveBayes}\n",
    "    \n",
    "Regression\n",
    "\n",
    "    org.apache.spark.mllib.regression.{LassoWithSGD, RidgeRegressionWithSGD}\n",
    "    \n",
    "Clustering\n",
    "\n",
    "    org.apache.spark.mllib.clustering.{KMeans, LDA}\n",
    "\n",
    "Dimensional reduction \n",
    "\n",
    "    mat.computePrincipalComponents\n",
    "    mat.computeSVD\n",
    "    \n",
    "Big Data TimeSeries\n",
    "\n",
    "    Spark-ts(Cloudera) https://github.com/sryza/spark-timeseries\n",
    "    \n",
    "Bid Data Neural Net\n",
    "    \n",
    "    TensorFrames https://github.com/databricks/tensorframes\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='Amazon'></a>  \n",
    "## The Clouds\n",
    "\n",
    "### AWS Ecosystem\n",
    "\n",
    "\n",
    "Courtesy Keith Steward slice Big Data Architectural Patterns and Best Practices on AWS http://www.slideshare.net/AmazonWebServices/big-data-architectural-patterns-and-best-practices-on-aws-67650658\n",
    "\n",
    "![](https://raw.githubusercontent.com/ronnnwu/DistributedDeepLearning/master/arch.png)\n",
    "\n",
    "\n",
    "Get estimate costs\n",
    "\n",
    "https://calculator.s3.amazonaws.com/index.html\n",
    "\n",
    "Hot - Cool means data transfer latency, throughput and the usage of storage is mainly for adding new data, or rewritting old data. ec2 (elastic computing cloud, auto scaling, virtual server), S3 (simple storage service, massive and redundant), Kinesis (stream, up to 7 days live data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='google'></a> \n",
    "### Google Clouds ML With TensorFlow\n",
    "\n",
    "\n",
    "Reference: \n",
    "\n",
    "Kaz Sato, Google Cloud Platform Empowers TensorFlow and Machine Learning\n",
    "http://www.slideshare.net/HadoopSummit/google-cloud-platform-empowers-tensorflow-and-machine-learning\n",
    "\n",
    "https://research.googleblog.com/2016/03/machine-learning-in-cloud-with.html\n",
    "\n",
    "Jeff Dean Talk on Google Cloud https://www.youtube.com/watch?v=ud2Ipnq0pTU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='cuda'></a>\n",
    "# Parallel with CUDA, C++\n",
    "\n",
    "![](http://images.anandtech.com/doci/6839/nvidia-cuda2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "name": "scala",
   "version": "2.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
