{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Reinforcement Learning with TensorFlow\n",
    "=============\n",
    "\n",
    "Ron Wu\n",
    "-------------\n",
    "\n",
    "11/12/16\n",
    "\n",
    "Reference:  \n",
    "David Silver, \"DeepMind Reinforcement Learning\", http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html<br>\n",
    "Denny Britz, \"Supplementory Notes on RL\", https://github.com/dennybritz/reinforcement-learning<br>\n",
    "John Schulman, Pieter Abbeel, \"Deep Reinforcement Learning\", http://rll.berkeley.edu/deeprlcourse/<br>\n",
    "Charles Isbell, Michael Littman, \"Reinforcement Learning\", https://www.udacity.com/course/reinforcement-learning--ud600\n",
    "\n",
    "### Contents\n",
    "\n",
    "\n",
    "- <a href=#intro>Introduction</a>\n",
    "- <a href =#mdp>Markov Decision Processes</a> \n",
    "<br><br> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='intro'></a>\n",
    "## Introduction\n",
    "\n",
    "In the last \"Convolutional Neural Networks for Image Processing, Recurrent Neural Networks for Natural Language Processing with TensorFlow\" note, I highlighted the triumph of artificial intelligence, AlphaGo (led by David Silver and Demis Hassabis) beat the top Go player in the world. AlphaGo used 12 layers of CNN to derive a value network and a policy network from 30,000,000 professional played games as initial training dataset, then it used reinforcement learning to refine it. \n",
    "\n",
    "Nature, \"Mastering the game of Go with deep neural networks and tree search\"\n",
    "http://www.nature.com/nature/journal/v529/n7587/full/nature16961.html or watch this talk https://youtu.be/aiwQsa_7ZIQ?t=300\n",
    "\n",
    "Reinforcement learning is the main focus of this note. The reason it is called deep reinforcement learning is that both CNN and RNN are big parts of it. CNN is used as external vision and leads to general purpose AI; RNN is used for predicting sequence of hidden states in the Markov decision model.  \n",
    "\n",
    "Nature, \"Human-level control through deep reinforcement learning\" http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a name ='mdp'></a>\n",
    "## Markov Decision Processes (MDP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Free Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Free Control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Function Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Policy Gradient Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrating Learning and Planning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration and Exploitation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Case Study: RL in Classic Games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
